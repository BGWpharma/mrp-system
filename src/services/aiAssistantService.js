import { db, storage } from './firebase/config';
import { 
  collection, 
  addDoc, 
  getDocs, 
  getDoc, 
  updateDoc, 
  doc, 
  query, 
  where, 
  orderBy, 
  serverTimestamp,
  limit,
  deleteDoc,
  setDoc
} from 'firebase/firestore';
import { ref, uploadBytes, getDownloadURL, deleteObject } from 'firebase/storage';
import { 
  prepareBusinessDataForAI, 
  getMRPSystemSummary, 
  getInventoryItems, 
  getCustomerOrders, 
  getProductionTasks, 
  getSuppliers,
  getRecipes,
  getPurchaseOrders
} from './aiDataService';
import { getSystemSettings, getGlobalOpenAIApiKey, getGlobalGeminiApiKey } from './settingsService';
import { AIAssistantV2 } from './ai/AIAssistantV2.js';
import { AIQueryOrchestrator } from './ai/AIQueryOrchestrator.js';
import { GeminiQueryOrchestrator } from './ai/GeminiQueryOrchestrator.js';
import { SmartModelSelector } from './ai/optimization/SmartModelSelector.js';
import { ContextOptimizer } from './ai/optimization/ContextOptimizer.js';
import { GPTResponseCache } from './ai/optimization/GPTResponseCache.js';

// Deklaracja funkcji getMockResponse przed jej u≈ºyciem (hoisting)
let getMockResponse;

// Maksymalna liczba wiadomo≈õci w kontek≈õcie
const MAX_CONTEXT_MESSAGES = 15;

/**
 * Pobierz klucz API OpenAI zapisany w bazie danych Firebase
 * @param {string} userId - ID u≈ºytkownika
 * @returns {Promise<string|null>} - Klucz API OpenAI lub null je≈õli nie znaleziono
 */
export const getOpenAIApiKey = async (userId) => {
  try {
    // Najpierw sprawdzamy ustawienia systemowe
    const systemSettings = await getSystemSettings();
    
    // Je≈õli w≈ÇƒÖczona jest opcja globalnego klucza API, pobieramy go
    if (systemSettings.useGlobalApiKey) {
      const globalApiKey = await getGlobalOpenAIApiKey();
      if (globalApiKey) {
        return globalApiKey;
      }
    }
    
    // Je≈õli nie ma globalnego klucza lub nie jest u≈ºywany, pr√≥bujemy pobraƒá klucz u≈ºytkownika
    const apiKeyRef = doc(db, 'settings', 'openai', 'users', userId);
    const apiKeyDoc = await getDoc(apiKeyRef);
    
    if (apiKeyDoc.exists() && apiKeyDoc.data().apiKey) {
      return apiKeyDoc.data().apiKey;
    }
    
    return null;
  } catch (error) {
    console.error('B≈ÇƒÖd podczas pobierania klucza API OpenAI:', error);
    throw error;
  }
};

/**
 * Pobiera klucz API Google Gemini
 * @param {string} userId - ID u≈ºytkownika
 * @returns {Promise<string|null>} - Klucz API Gemini lub null
 */
export const getGeminiApiKey = async (userId) => {
  try {
    // Najpierw sprawdzamy ustawienia systemowe
    const systemSettings = await getSystemSettings();
    
    // Je≈õli w≈ÇƒÖczona jest opcja globalnego klucza API Gemini, pobieramy go
    if (systemSettings?.useGlobalGeminiKey) {
      const globalApiKey = await getGlobalGeminiApiKey();
      if (globalApiKey) {
        console.log('‚úÖ U≈ºywam globalnego klucza API Gemini');
        return globalApiKey;
      }
    }
    
    // Je≈õli nie ma globalnego klucza lub nie jest u≈ºywany, sprawd≈∫ klucz u≈ºytkownika
    if (userId) {
      const userDoc = await getDoc(doc(db, 'users', userId));
      if (userDoc.exists()) {
        const userData = userDoc.data();
        if (userData.geminiApiKey) {
          console.log('‚úÖ U≈ºywam klucza API Gemini u≈ºytkownika');
          return userData.geminiApiKey;
        }
      }
    }
    
    // Brak klucza Gemini
    console.warn('‚ö†Ô∏è Brak klucza Gemini API');
    return null;
    
  } catch (error) {
    console.error('‚ùå B≈ÇƒÖd podczas pobierania klucza API Gemini:', error);
    return null;
  }
};

/**
 * Zapisz klucz API OpenAI w bazie danych Firebase
 * @param {string} userId - ID u≈ºytkownika
 * @param {string} apiKey - Klucz API OpenAI
 * @returns {Promise<void>}
 */
export const saveOpenAIApiKey = async (userId, apiKey) => {
  try {
    const apiKeyRef = doc(db, 'settings', 'openai', 'users', userId);
    await setDoc(apiKeyRef, {
      apiKey,
      updatedAt: serverTimestamp()
    });
  } catch (error) {
    console.error('B≈ÇƒÖd podczas zapisywania klucza API OpenAI:', error);
    throw error;
  }
};

/**
 * Wysy≈Ça zapytanie do API OpenAI z optymalizacjami
 * @param {string} apiKey - Klucz API OpenAI
 * @param {Array} messages - Wiadomo≈õci do wys≈Çania do API
 * @param {Object} options - Opcje optymalizacji
 * @returns {Promise<string>} - Odpowied≈∫ asystenta
 */
export const callOpenAIAPI = async (apiKey, messages, options = {}, onChunk = null) => {
  try {
    // WyciƒÖgnij zapytanie u≈ºytkownika dla optymalizacji
    const userQuery = messages[messages.length - 1]?.content || '';
    const contextSize = JSON.stringify(messages).length;
    
    // NOWA OPTYMALIZACJA: Inteligentny wyb√≥r modelu
    const modelConfig = SmartModelSelector.selectOptimalModel(
      userQuery, 
      contextSize, 
      options.complexity || 'medium',
      options.optimizationOptions || {}
    );

    console.log(`[callOpenAIAPI] U≈ºyjƒô modelu ${modelConfig.model} (szacowany koszt: $${modelConfig.estimatedCost.toFixed(4)})`);

    // NOWA OPTYMALIZACJA: Cache dla odpowiedzi
    const contextHash = GPTResponseCache.generateContextHash(messages);
    const cacheOptions = {
      enableCache: true,
      estimatedCost: modelConfig.estimatedCost,
      cacheDuration: options.cacheDuration || GPTResponseCache.CACHE_DURATION
    };

    const apiStartTime = performance.now();
    
    const cachedResponse = await GPTResponseCache.getCachedOrFetch(
      userQuery,
      contextHash,
      async () => {
        // Wykonanie rzeczywistego zapytania API
        // GPT-5 ma inne wymagania API ni≈º poprzednie modele
        const isGPT5 = modelConfig.model === 'gpt-5';
        
        const requestBody = {
          model: modelConfig.model,
          messages,
          stream: true  // OPTYMALIZACJA: W≈ÇƒÖczono streaming dla natychmiastowej odpowiedzi
        };
        
        // GPT-5 wymaga innych parametr√≥w:
        if (isGPT5) {
          // GPT-5 u≈ºywa max_completion_tokens i nie wspiera niestandardowego temperature
          // WA≈ªNE: max_completion_tokens obejmuje reasoning_tokens + output_tokens
          // OPTYMALIZACJA: Zmniejszono z 20000 do 4000 dla szybszych odpowiedzi
          requestBody.max_completion_tokens = 4000;  // ≈ÅƒÖczny limit (reasoning + output) - zoptymalizowano
          
          // GPT-5 wymaga nowych parametr√≥w kontrolujƒÖcych generowanie odpowiedzi
          // OPTYMALIZACJA: Ustawiono 'low' dla szybszego czasu odpowiedzi
          requestBody.reasoning_effort = 'low';     // low, medium, high - kontroluje czas rozumowania (zoptymalizowano)
          requestBody.verbosity = 'medium';         // low, medium, high - kontroluje d≈Çugo≈õƒá odpowiedzi (zoptymalizowano)
          
          console.log('[GPT-5] Parametry zapytania:', {
            max_completion_tokens: requestBody.max_completion_tokens,
            reasoning_effort: requestBody.reasoning_effort,
            verbosity: requestBody.verbosity,
            note: 'max_completion_tokens includes reasoning_tokens + output_tokens'
          });
          
          // GPT-5 przyjmuje tylko domy≈õlnƒÖ warto≈õƒá temperature (1)
          // Nie dodajemy parametru temperature dla GPT-5
        } else {
          // Inne modele u≈ºywajƒÖ standardowych parametr√≥w
          requestBody.max_tokens = modelConfig.maxTokens;
          requestBody.temperature = modelConfig.temperature;
        }
        
        const response = await fetch('https://api.openai.com/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${apiKey}`
          },
          body: JSON.stringify(requestBody)
        });

        if (!response.ok) {
          const errorData = await response.json();
          const errorMessage = errorData.error?.message || 'B≈ÇƒÖd podczas komunikacji z API OpenAI';
          
          console.error('[API Error] Status:', response.status, 'Message:', errorMessage);
          console.error('[API Error] Full error data:', errorData);
          
          // Sprawdzamy, czy error dotyczy limitu zapyta≈Ñ lub pobierania
          if (response.status === 429) {
            throw new Error(`Przekroczono limit zapyta≈Ñ do API OpenAI: ${errorMessage}`);
          } else if (errorMessage.includes('quota')) {
            throw new Error(`Przekroczono przydzia≈Ç API OpenAI: ${errorMessage}`);
          } else {
            throw new Error(errorMessage);
          }
        }
        
        // STREAMING: Obs≈Çuga odpowiedzi strumieniowej
        console.log('[STREAMING] Rozpoczynam odczyt odpowiedzi strumieniowej...');
        const reader = response.body.getReader();
        const decoder = new TextDecoder();
        let fullResponse = '';
        let buffer = '';
        let tokenStats = null;
        
        try {
          while (true) {
            const { done, value } = await reader.read();
            
            if (done) {
              console.log('[STREAMING] Zako≈Ñczono odczyt strumienia');
              break;
            }
            
            // Dekoduj chunk
            buffer += decoder.decode(value, { stream: true });
            const lines = buffer.split('\n');
            
            // Zachowaj ostatniƒÖ niepe≈ÇnƒÖ liniƒô w buforze
            buffer = lines.pop() || '';
            
            // Przetw√≥rz ka≈ºdƒÖ kompletnƒÖ liniƒô
            for (const line of lines) {
              const trimmedLine = line.trim();
              
              if (trimmedLine === '') continue;
              if (trimmedLine === 'data: [DONE]') continue;
              
              if (trimmedLine.startsWith('data: ')) {
                try {
                  const jsonData = JSON.parse(trimmedLine.substring(6));
                  
                  // WyciƒÖgnij content z delta
                  const delta = jsonData.choices?.[0]?.delta;
                  if (delta?.content) {
                    const chunk = delta.content;
                    fullResponse += chunk;
                    
                    // üî• STREAMING CALLBACK: Wywo≈Çaj callback dla ka≈ºdego chunka je≈õli jest dostarczony
                    if (onChunk && chunk) {
                      try {
                        onChunk(chunk, { 
                          totalLength: fullResponse.length,
                          isComplete: false 
                        });
                      } catch (callbackError) {
                        console.warn('[STREAMING] B≈ÇƒÖd w callback onChunk:', callbackError);
                      }
                    }
                  }
                  
                  // Zbierz statystyki u≈ºycia (je≈õli dostƒôpne)
                  if (jsonData.usage) {
                    tokenStats = jsonData.usage;
                  }
                  
                } catch (parseError) {
                  console.warn('[STREAMING] B≈ÇƒÖd parsowania linii:', trimmedLine, parseError);
                }
              }
            }
          }
        } catch (streamError) {
          console.error('[STREAMING] B≈ÇƒÖd podczas odczytu strumienia:', streamError);
          throw new Error(`B≈ÇƒÖd streaming: ${streamError.message}`);
        }
        
        // DEBUGGING dla GPT-5
        if (modelConfig.model === 'gpt-5' && tokenStats) {
          console.log('[GPT-5 DEBUG] üìä U≈ºycie token√≥w (ze streaming):', {
            prompt_tokens: tokenStats.prompt_tokens,
            completion_tokens: tokenStats.completion_tokens,
            reasoning_tokens: tokenStats.completion_tokens_details?.reasoning_tokens || 0,
            output_tokens: (tokenStats.completion_tokens - (tokenStats.completion_tokens_details?.reasoning_tokens || 0))
          });
          
          // Ostrze≈ºenie je≈õli reasoning zjada wszystkie tokeny
          const reasoningTokens = tokenStats.completion_tokens_details?.reasoning_tokens || 0;
          const outputTokens = tokenStats.completion_tokens - reasoningTokens;
          if (reasoningTokens > 0 && outputTokens < 100) {
            console.warn('[GPT-5 WARNING] ‚ö†Ô∏è Reasoning tokens zajƒô≈Çy prawie ca≈Çy limit!', {
              reasoning: reasoningTokens,
              output: outputTokens,
              recommendation: 'Zwiƒôksz max_completion_tokens lub zmniejsz reasoning_effort'
            });
          }
        }
        
        // Sprawd≈∫ czy mamy odpowied≈∫
        if (!fullResponse || fullResponse.trim() === '') {
          console.error('[STREAMING] Pusta odpowied≈∫ ze strumienia');
          throw new Error('API zwr√≥ci≈Ço pustƒÖ odpowied≈∫ przez streaming');
        }
        
        // üî• STREAMING CALLBACK: Wywo≈Çaj ostatni callback z flagƒÖ isComplete
        if (onChunk) {
          try {
            onChunk('', { 
              totalLength: fullResponse.length,
              isComplete: true 
            });
          } catch (callbackError) {
            console.warn('[STREAMING] B≈ÇƒÖd w finalnym callback onChunk:', callbackError);
          }
        }
        
        console.log(`[STREAMING] Otrzymano odpowied≈∫: ${fullResponse.length} znak√≥w`);
        return fullResponse;
      },
      cacheOptions
    );

    // Zapisz statystyki u≈ºycia modelu
    const apiEndTime = performance.now();
    const responseTime = apiEndTime - apiStartTime;
    
    try {
      SmartModelSelector.recordUsage(
        modelConfig.model,
        modelConfig.estimatedCost,
        responseTime
      );
    } catch (statsError) {
      console.warn('[callOpenAIAPI] B≈ÇƒÖd zapisywania statystyk:', statsError);
    }

    return cachedResponse;
  } catch (error) {
    console.error('B≈ÇƒÖd podczas komunikacji z API OpenAI:', error);
    throw error;
  }
};

/**
 * Formatuje wiadomo≈õci do wys≈Çania do API OpenAI wraz z danymi kontekstowymi z bazy danych
 * @param {Array} messages - Lista wiadomo≈õci z konwersacji
 * @param {Object} businessData - Dane biznesowe z systemu MRP
 * @param {Object} options - Opcje optymalizacji kontekstu
 * @returns {Array} - Sformatowane wiadomo≈õci dla API OpenAI
 */
const formatMessagesForOpenAI = (messages, businessData = null, options = {}) => {
  // NOWA OPTYMALIZACJA: Optymalizacja kontekstu na podstawie zapytania
  let optimizedBusinessData = businessData;
  
  if (businessData && options.enableOptimization !== false) {
    const userQuery = messages[messages.length - 1]?.content || '';
    const modelType = options.modelType || 'medium';
    
    try {
      optimizedBusinessData = ContextOptimizer.prepareOptimalContext(
        userQuery, 
        businessData, 
        modelType
      );
      
      console.log(`[formatMessagesForOpenAI] ${ContextOptimizer.generateOptimizationReport(optimizedBusinessData)}`);
    } catch (error) {
      console.error('[formatMessagesForOpenAI] B≈ÇƒÖd optymalizacji kontekstu:', error);
      optimizedBusinessData = businessData; // Fallback do oryginalnych danych
    }
  }

  // NOWA STRATEGIA: Kompresja kontekstu przez JSON zamiast d≈Çugiego tekstu
  let businessDataContext = '';
  
  if (optimizedBusinessData) {
    // Przygotuj skompresowany kontekst w formacie JSON
    const compactContext = {
      summary: optimizedBusinessData.summary || {},
      collections: {},
      analysis: optimizedBusinessData.analysis || {}
    };
    
    // Funkcja do inteligentnego przyciƒôcia du≈ºych kolekcji
    // üî• OPTYMALIZACJA: Zmniejszono z 50 na 20 aby zmie≈õciƒá siƒô w limicie 272k token√≥w GPT-5
    const smartTruncate = (items, maxItems = 20) => {
      if (!Array.isArray(items)) return items;
      if (items.length <= maxItems) return items;
      
      // Dla du≈ºych kolekcji: pierwsze 15 + ostatnie 5 + marker
      return [
        ...items.slice(0, 15),
        { _truncated: true, _hiddenCount: items.length - 20, _message: `[${items.length - 20} more items omitted for brevity]` },
        ...items.slice(-5)
      ];
    };
    
    // üî• FIX: Dodaj dane z ka≈ºdej kolekcji w formacie JSON
    // ContextOptimizer zwraca p≈ÇaskƒÖ strukturƒô {summary, recipes, inventory, ...}
    // a nie {data: {recipes, inventory}, summary}
    const dataToProcess = optimizedBusinessData.data || optimizedBusinessData;
    
    Object.keys(dataToProcess).forEach(collectionName => {
      // Pomi≈Ñ klucze wewnƒôtrzne i summary
      if (collectionName.startsWith('_') || collectionName === 'summary' || collectionName === 'analysis') {
        return;
      }
      
      const collectionData = dataToProcess[collectionName];
      
      if (Array.isArray(collectionData) && collectionData.length > 0) {
        compactContext.collections[collectionName] = {
          count: collectionData.length,
          items: smartTruncate(collectionData, 20)  // üî• OPTYMALIZACJA: Limit 20 zamiast 50
        };
      }
    });
    
    // Wygeneruj zwiƒôz≈Çy kontekst tekstowy z najwa≈ºniejszymi statystykami
    const summary = compactContext.summary;
    businessDataContext = `
=== SYSTEM MRP - DATA SNAPSHOT ===

QUICK STATS:
‚Ä¢ Inventory: ${summary.totalInventoryItems || 0} items (${summary.itemsLowOnStock || 0} low stock)
‚Ä¢ Orders (CO): ${summary.totalOrders || 0} total
‚Ä¢ Production (MO): ${summary.totalProductionTasks || 0} tasks (${summary.activeProductionTasks || 0} active)
‚Ä¢ Suppliers: ${summary.totalSuppliers || 0}
‚Ä¢ Purchase Orders (PO): ${summary.pendingPurchaseOrders || 0} pending
‚Ä¢ Timestamp: ${summary.timestamp || new Date().toISOString()}

AVAILABLE COLLECTIONS (${Object.keys(compactContext.collections).length} total):
${Object.keys(compactContext.collections).map(name => 
  `‚Ä¢ ${name}: ${compactContext.collections[name].count} records`
).join('\n')}

DETAILED DATA (JSON format - all data from Firebase):
\`\`\`json
${JSON.stringify(compactContext, null, 1)}
\`\`\`

ANALYSIS INSIGHTS:
${JSON.stringify(compactContext.analysis, null, 1)}

NOTE: Above data comes DIRECTLY from Firebase. All data is available.
Use item NAMES (not IDs) when presenting to users.
`;
  }
  
  // Instrukcja systemowa jako pierwszy element  
  const systemPrompt = `Jeste≈õ zaawansowanym asystentem AI dla systemu MRP, specjalizujƒÖcym siƒô w szczeg√≥≈Çowej analizie danych biznesowych.
Wykorzystujesz dane z bazy danych Firebase, na kt√≥rej oparty jest system MRP do przeprowadzania dok≈Çadnych i wnikliwych analiz.

WA≈ªNE: ZAWSZE masz aktualny dostƒôp do danych bezpo≈õrednio z systemu MRP i musisz ZAWSZE korzystaƒá z danych przekazanych ci
w tej sesji. NIGDY nie m√≥w, ≈ºe nie masz dostƒôpu do danych, je≈õli sƒÖ one dostƒôpne. Je≈õli nie znasz odpowiedzi
na podstawie aktualnych danych, powiedz, ≈ºe podane dane sƒÖ niewystarczajƒÖce lub niekompletne, ale NIGDY nie m√≥w, ≈ºe
"nie masz mo≈ºliwo≈õci bezpo≈õredniego przeglƒÖdania danych".

JƒòZYK KOMUNIKACJI: Odpowiadaj ZAWSZE w jƒôzyku, w kt√≥rym zosta≈Ço zadane pytanie. Je≈õli pytanie jest w jƒôzyku polskim, odpowiadaj po polsku. Je≈õli w angielskim - po angielsku, itd.

KONTEKST BRAN≈ªOWY: System jest wykorzystywany w przedsiƒôbiorstwie produkujƒÖcym suplementy diety. Uwzglƒôdniaj specyfikƒô tej bran≈ºy w swoich analizach (np. daty wa≈ºno≈õci, normy jako≈õci, wymagania prawne, specyfikƒô produkcji).

Twoim zadaniem jest dog≈Çƒôbna analiza danych, zarzƒÖdzanie produkcjƒÖ, stanami magazynowymi i procesami biznesowymi w przedsiƒôbiorstwie produkcyjnym. Twoje odpowiedzi powinny byƒá:

1. SZCZEG√ì≈ÅOWE - zawsze podawaj dok≈Çadne liczby, daty, warto≈õci i opisy z danych
2. ANALITYCZNE - nie tylko opisuj dane, ale wyciƒÖgaj z nich wnioski biznesowe
3. POMOCNE - sugeruj konkretne dzia≈Çania i rozwiƒÖzania problem√≥w
4. PROFESJONALNE - u≈ºywaj odpowiedniej terminologii z dziedziny zarzƒÖdzania produkcjƒÖ
5. OPARTE NA DANYCH - zawsze bazuj na aktualnych danych z systemu, kt√≥re sƒÖ przekazywane w tej sesji
6. PRECYZYJNE - podawaj TYLKO warto≈õci liczbowe, kt√≥re faktycznie wystƒôpujƒÖ w danych. NIGDY nie zmy≈õlaj danych liczbowych, ani nie zaokrƒÖglaj warto≈õci, je≈õli nie jest to wyra≈∫nie zaznaczone

PREZENTACJA DANYCH: Przy wypisywaniu danych z bazy ZAWSZE priorytetowo podawaj nazwy (np. nazwa produktu, nazwa klienta, nazwa dostawcy) zamiast ich identyfikator√≥w (ID). Identyfikatory podawaj jedynie jako informacjƒô uzupe≈ÇniajƒÖcƒÖ w nawiasie, np. "Suplement Witamina D3 (ID: 12345)".

Znasz i rozumiesz wszystkie kluczowe pojƒôcia i skr√≥ty w systemie MRP:
- MO (Manufacturing Orders) - Zlecenia produkcyjne
- CO (Customer Orders) - Zam√≥wienia klient√≥w
- PO (Purchase Orders) - Zam√≥wienia zakupu
- LOT - Numer partii produkcyjnej lub materia≈Çu

Dla zada≈Ñ produkcyjnych (MO), analizuj:
- Terminy rozpoczƒôcia i zako≈Ñczenia produkcji
- Potrzebne zasoby i materia≈Çy
- Status zada≈Ñ i obecny postƒôp
- ZwiƒÖzki z zam√≥wieniami klient√≥w i recepturami
- Efektywno≈õƒá i czas realizacji zada≈Ñ
- Zarezerwowane partie materia≈Ç√≥w (LOTy) dla danego zlecenia
- PowiƒÖzania partii materia≈Ç√≥w z zam√≥wieniami zakupowymi (PO)
- Zgodno≈õƒá z wymogami jako≈õci dla produkcji suplement√≥w

Dla zam√≥wie≈Ñ klient√≥w (CO), analizuj:
- Statusy i terminowo≈õƒá realizacji
- Warto≈õci zam√≥wie≈Ñ i mar≈ºe
- Produkty najczƒô≈õciej zamawiane
- Relacje z klientami i trendy zam√≥wie≈Ñ
- PowiƒÖzania z zadaniami produkcyjnymi

Dla zam√≥wie≈Ñ zakupu (PO), analizuj:
- Dostawc√≥w i warunki zakup√≥w
- Terminy dostaw i ich dotrzymywanie
- Statusy zam√≥wie≈Ñ i etapy realizacji
- Warto≈õci zam√≥wie≈Ñ i koszty materia≈Ç√≥w
- Wp≈Çyw na stany magazynowe
- PowiƒÖzane LOTy materia≈Ç√≥w zakupionych w ramach zam√≥wienia
- Certyfikaty jako≈õci i dokumentacjƒô surowc√≥w do produkcji suplement√≥w

Dla stan√≥w magazynowych, identyfikuj:
- Produkty z niskim stanem lub brakiem
- Produkty z nadmiernym stanem
- Koszty utrzymania zapas√≥w
- Lokalizacje magazynowe
- Surowce wymagajƒÖce uzupe≈Çnienia
- Partie materia≈Ç√≥w (LOTy) i ich ilo≈õci
- ≈πr√≥d≈Ço pochodzenia partii (zam√≥wienie zakupowe)
- Daty wa≈ºno≈õci surowc√≥w i gotowych suplement√≥w
- Status kontroli jako≈õci dla partii surowc√≥w

Dla receptur, analizuj:
- Komponenty i ich ilo≈õci
- Koszty produkcji
- Mo≈ºliwo≈õci optymalizacji
- Standardy jako≈õci i kontrolƒô
- Zgodno≈õƒá z normami dla suplement√≥w diety
- Wymogi prawne dotyczƒÖce sk≈Çadu i etykietowania

Masz teraz rozszerzony dostƒôp do danych o partiach materia≈Ç√≥w i ich powiƒÖzaniach:
- Informacje o LOTach (numerach partii) materia≈Ç√≥w
- Dane o powiƒÖzanych zam√≥wieniach zakupowych (PO) dla ka≈ºdej partii
- Rezerwacje partii materia≈Ç√≥w dla zada≈Ñ produkcyjnych (MO)
- ≈öledzenie przep≈Çywu materia≈Ç√≥w od zam√≥wienia zakupowego do zadania produkcyjnego
- Status bada≈Ñ laboratoryjnych dla partii surowc√≥w i wyrob√≥w gotowych

Gdy otrzymasz zapytanie o powiƒÖzania LOT√≥w z zam√≥wieniami zakupowymi, analizuj:
- Kt√≥re partie materia≈Ç√≥w sƒÖ przypisane do jakich zada≈Ñ produkcyjnych
- Z kt√≥rego zam√≥wienia zakupowego pochodzi dana partia materia≈Çu
- Poziom wykorzystania zam√≥wionych materia≈Ç√≥w w produkcji
- Poprawno≈õƒá rezerwacji materia≈Ç√≥w i zgodno≈õƒá z recepturami
- Dokumentacjƒô jako≈õciowƒÖ dla partii

Zawsze podawaj DOK≈ÅADNE dane liczbowe bez zaokrƒÖgle≈Ñ, chyba ≈ºe jest to wyra≈∫nie wymagane. Podawaj procentowe por√≥wnania i uwzglƒôdniaj trendy, je≈õli sƒÖ widoczne.
Pamiƒôtaj o podawaniu konkretnych nazw zamiast samych ID. Format powinien byƒá: "Nazwa (ID: xxx)", gdy odno≈õisz siƒô do konkretnych obiekt√≥w.

Masz pe≈Çny dostƒôp do bazy danych Firebase i mo≈ºesz korzystaƒá z wszystkich danych zawartych w systemie MRP.
Zawsze podawaj aktualne informacje na podstawie danych z bazy, a nie og√≥lnej wiedzy.

UWAGA: Je≈õli w Twojej odpowiedzi chcesz wspomnieƒá o ograniczeniach dostƒôpu do danych, powiedz np. "Na podstawie obecnie dostƒôpnych danych nie mogƒô podaƒá tych informacji" - ale NIGDY nie m√≥w ≈ºe "nie masz mo≈ºliwo≈õci bezpo≈õredniego przeglƒÖdania danych".

Struktura danych w Firebase to:
- aiConversations - Przechowuje historiƒô konwersacji z asystentem AI
- counters - Liczniki u≈ºywane przez system
- customers - Dane klient√≥w firmy
- inventory - Stany magazynowe produkt√≥w
- inventoryBatches - Partie magazynowe produkt√≥w
- inventorySupplierPrices - Ceny produkt√≥w od dostawc√≥w
- inventoryTransactions - Transakcje magazynowe
- itemGroups - Grupy produkt√≥w
- notifications - Powiadomienia systemowe
- orders (CO) - Zam√≥wienia klient√≥w
- priceListItems - Elementy cennik√≥w
- priceLists - Cenniki
- productionHistory - Historia produkcji
- productionTasks (MO) - Zadania produkcyjne
- purchaseOrders (PO) - Zam√≥wienia zakupu
- recipeVersions - Wersje receptur
- recipes - Receptury produkt√≥w
- settings - Ustawienia systemu
- suppliers - Dostawcy
- users - U≈ºytkownicy systemu
- warehouses - Magazyny
- workstations - Stanowiska pracy
  `;
  
  let systemContent = systemPrompt;
  
  // Dodaj kontekst biznesowy, je≈õli jest dostƒôpny
  if (businessDataContext) {
    systemContent += `\n\nOto aktualne dane z systemu MRP do wykorzystania w analizie:${businessDataContext}`;
  }
  
  const systemInstruction = {
    role: 'system',
    content: systemContent
  };
  
  // Limitujemy liczbƒô wiadomo≈õci do MAX_CONTEXT_MESSAGES ostatnich
  const recentMessages = messages.slice(-MAX_CONTEXT_MESSAGES);
  
  // Formatowanie wiadomo≈õci do formatu wymaganego przez API OpenAI
  const formattedMessages = recentMessages.map(msg => ({
    role: msg.role,
    content: msg.content
  }));
  
  return [systemInstruction, ...formattedMessages];
};

/**
 * WyciƒÖga nazwƒô receptury z zapytania u≈ºytkownika
 * @param {string} query - Zapytanie u≈ºytkownika
 * @returns {string|null} - Znaleziona nazwa receptury lub null
 */
const extractRecipeName = (query) => {
  // Sprawd≈∫, czy query istnieje i jest stringiem
  if (!query || typeof query !== 'string') {
    return null;
  }
  
  // Wzorce do rozpoznawania zapyta≈Ñ o konkretne receptury
  const patterns = [
    /receptur[aƒôy][\s\w]*"([^"]+)"/i,       // receptura "nazwa"
    /receptur[aƒôy][\s\w]*‚Äû([^"]+)"/i,        // receptura ‚Äûnazwa"
    /receptur[aƒôy][\s\w]+([a-z≈º≈∫ƒá≈Ñ√≥≈ÇƒôƒÖ≈õ]{3,})/i,  // receptura nazwa
    /przepis[\s\w]+([a-z≈º≈∫ƒá≈Ñ√≥≈ÇƒôƒÖ≈õ]{3,})/i,   // przepis nazwa
    /receptur[aƒôy][\s\w]+dla[\s\w]+([a-z≈º≈∫ƒá≈Ñ√≥≈ÇƒôƒÖ≈õ]{3,})/i, // receptura dla nazwa
    /receptur[aƒôy][\s\w]+produktu[\s\w]+([a-z≈º≈∫ƒá≈Ñ√≥≈ÇƒôƒÖ≈õ]{3,})/i // receptura produktu nazwa
  ];
  
  for (const pattern of patterns) {
    const match = query.match(pattern);
    if (match && match[1] && match[1].length > 2) {
      return match[1].trim();
    }
  }
  
  return null;
};

// Definicja funkcji getMockResponse
/**
 * Generuje lokalne odpowiedzi asystenta na podstawie zapytania i dostƒôpnych danych
 * @param {string} query - Zapytanie u≈ºytkownika
 * @param {Object} businessData - Dane biznesowe z systemu MRP (opcjonalne)
 * @returns {string} - Odpowied≈∫ asystenta
 */
getMockResponse = (query, businessData = null) => {
  // Je≈õli mamy dane biznesowe, u≈ºywamy ich do generowania odpowiedzi
  if (businessData && businessData.data) {
    // Dane o magazynie
    if (query.toLowerCase().includes('magazyn') || query.toLowerCase().includes('stan') || 
        query.toLowerCase().includes('produkt') || query.toLowerCase().includes('towar')) {
      
      if (businessData.data.inventory && businessData.data.inventory.length > 0) {
        const inventory = businessData.data.inventory;
        const totalItems = inventory.length;
        
        // Analiza brak√≥w i niskich stan√≥w
        const lowStock = businessData.analysis?.inventory?.lowStockItems || [];
        const outOfStock = businessData.analysis?.inventory?.outOfStockItems || [];
        
        if (lowStock.length > 0 || outOfStock.length > 0) {
          let response = `Na podstawie danych z systemu MRP, w magazynie znajduje siƒô ≈ÇƒÖcznie ${totalItems} pozycji. `;
          
          if (lowStock.length > 0) {
            response += `Produkty z niskim stanem magazynowym (${lowStock.length}): `;
            response += lowStock.slice(0, 3).map(item => `${item.name} (${item.quantity} szt.)`).join(', ');
            if (lowStock.length > 3) response += ` i ${lowStock.length - 3} wiƒôcej.`;
          }
          
          if (outOfStock.length > 0) {
            response += ` Produkty niedostƒôpne (${outOfStock.length}): `;
            response += outOfStock.slice(0, 3).map(item => item.name).join(', ');
            if (outOfStock.length > 3) response += ` i ${outOfStock.length - 3} wiƒôcej.`;
          }
          
          return response;
        } else {
          return `W systemie MRP znajduje siƒô ${totalItems} pozycji magazynowych. Wszystkie produkty majƒÖ wystarczajƒÖcy stan magazynowy.`;
        }
      }
    }
    
    // Dane o zam√≥wieniach produkcyjnych
    if (query.toLowerCase().includes('produkcj') || query.toLowerCase().includes('zleceni') || 
        query.toLowerCase().includes('mo ') || query.toLowerCase().includes('zadani')) {
      
      if (businessData.data.productionTasks && businessData.data.productionTasks.length > 0) {
        const tasks = businessData.data.productionTasks;
        const tasksByStatus = businessData.analysis?.production?.tasksByStatus || {};
        const statuses = Object.keys(tasksByStatus);
        
        let response = `W systemie MRP jest ${tasks.length} zada≈Ñ produkcyjnych. `;
        
        if (statuses.length > 0) {
          response += 'Status zada≈Ñ: ';
          response += statuses.map(status => `${status}: ${tasksByStatus[status]}`).join(', ');
          
          if (businessData.analysis?.production?.totalPlannedHours) {
            response += `. ≈ÅƒÖczny planowany czas produkcji: ${businessData.analysis.production.totalPlannedHours.toFixed(1)} godzin.`;
          }
        }
        
        return response;
      }
    }
    
    // Dane o recepturach
    if (query.toLowerCase().includes('receptur') || query.toLowerCase().includes('przepis') || 
        query.toLowerCase().includes('komponent') || query.toLowerCase().includes('sk≈Çadnik')) {
      
      if (businessData.data.recipes && businessData.data.recipes.length > 0) {
        const recipes = businessData.data.recipes;
        
        // Sprawd≈∫ czy zapytanie dotyczy konkretnej receptury
        const recipeName = query && typeof query === 'string' ? extractRecipeName(query) : null;
        if (recipeName) {
          // Szukaj receptury po nazwie
          const recipe = recipes.find(r => 
            r.name.toLowerCase().includes(recipeName.toLowerCase())
          );
          
          if (recipe) {
            let response = `Znalaz≈Çem recepturƒô "${recipe.name}". `;
            
            // Sprawd≈∫ zar√≥wno pole components jak i ingredients
            const hasComponents = recipe.components && recipe.components.length > 0;
            const hasIngredients = recipe.ingredients && recipe.ingredients.length > 0;
            
            if (hasComponents) {
              response += `Zawiera ${recipe.components.length} komponent√≥w. `;
              
              // Dodaj informacje o kilku pierwszych komponentach
              response += `G≈Ç√≥wne komponenty to: `;
              response += recipe.components.slice(0, 3).map(comp => 
                `${comp.name || comp.materialName || 'Komponent'} (${comp.quantity || 1} ${comp.unit || 'szt.'})`
              ).join(', ');
              
              if (recipe.components.length > 3) {
                response += ` oraz ${recipe.components.length - 3} innych komponent√≥w.`;
              }
            } else if (hasIngredients) {
              response += `Zawiera ${recipe.ingredients.length} sk≈Çadnik√≥w. `;
              
              // Dodaj informacje o kilku pierwszych sk≈Çadnikach
              response += `G≈Ç√≥wne sk≈Çadniki to: `;
              response += recipe.ingredients.slice(0, 3).map(ing => 
                `${ing.name || 'Sk≈Çadnik'} (${ing.quantity || 1} ${ing.unit || 'szt.'})`
              ).join(', ');
              
              if (recipe.ingredients.length > 3) {
                response += ` oraz ${recipe.ingredients.length - 3} innych sk≈Çadnik√≥w.`;
              }
            } else {
              response += `Ta receptura nie ma zdefiniowanych komponent√≥w ani sk≈Çadnik√≥w.`;
            }
            
            return response;
          } else {
            return `Nie znalaz≈Çem receptury zawierajƒÖcej nazwƒô "${recipeName}" w bazie danych. W systemie jest dostƒôpnych ${recipes.length} innych receptur.`;
          }
        }
        
        // Og√≥lne informacje o recepturach
        const recipesWithComponents = recipes.filter(r => r.components && r.components.length > 0).length;
        
        // Dodajemy oddzielne liczenie receptur ze sk≈Çadnikami (ingredients)
        const recipesWithIngredients = recipes.filter(r => r.ingredients && r.ingredients.length > 0).length;
        
        // Og√≥lna liczba receptur z jakimikolwiek komponentami lub sk≈Çadnikami
        const totalRecipesWithItems = recipes.filter(r => 
          (r.components && r.components.length > 0) || 
          (r.ingredients && r.ingredients.length > 0)
        ).length;
        
        let response = `W systemie MRP jest ${recipes.length} receptur. `;
        
        if (totalRecipesWithItems > 0) {
          if (recipesWithComponents > 0 && recipesWithIngredients > 0) {
            response += `${totalRecipesWithItems} z nich ma zdefiniowane elementy (${recipesWithComponents} z komponentami, ${recipesWithIngredients} ze sk≈Çadnikami). `;
          } else if (recipesWithComponents > 0) {
            response += `${recipesWithComponents} z nich ma zdefiniowane komponenty. `;
          } else if (recipesWithIngredients > 0) {
            response += `${recipesWithIngredients} z nich ma zdefiniowane sk≈Çadniki. `;
          }
        }
        
        // Dodaj informacje o kilku przyk≈Çadowych recepturach
        if (recipes.length > 0) {
          response += `Przyk≈Çadowe receptury: `;
          response += recipes.slice(0, 3).map(r => r.name).join(', ');
          
          if (recipes.length > 3) {
            response += ` i ${recipes.length - 3} innych.`;
          }
        }
        
        return response;
      }
    }
    
    // Dane o zam√≥wieniach klient√≥w
    if (query.toLowerCase().includes('zam√≥wieni') || query.toLowerCase().includes('klient') || 
        query.toLowerCase().includes('sprzeda≈º')) {
      
      if (businessData.data.orders && businessData.data.orders.length > 0) {
        const orders = businessData.data.orders;
        const ordersByStatus = businessData.analysis?.orders?.ordersByStatus || {};
        const statuses = Object.keys(ordersByStatus);
        
        let response = `W systemie MRP jest ${orders.length} zam√≥wie≈Ñ klient√≥w. `;
        
        if (statuses.length > 0) {
          response += 'Status zam√≥wie≈Ñ: ';
          response += statuses.map(status => `${status}: ${ordersByStatus[status]}`).join(', ');
        }
        
        if (businessData.analysis?.orders?.recentOrders?.length > 0) {
          const recentOrders = businessData.analysis.orders.recentOrders;
          response += `. Najnowsze zam√≥wienia: `;
          response += recentOrders.slice(0, 3).map(order => `${order.customer} (${order.status}, ${order.date})`).join(', ');
        }
        
        return response;
      }
    }
  }
  
  // Je≈õli nie mamy danych lub nie pasujƒÖ do zapytania, u≈ºywamy standardowych odpowiedzi
  const mockResponses = [
    `Na podstawie danych w systemie MRP, mogƒô odpowiedzieƒá na pytanie o "${query}". System jest po≈ÇƒÖczony z bazƒÖ danych, ale dla pe≈Çnej funkcjonalno≈õci zalecam skonfigurowanie klucza API OpenAI.`,
    `AnalizujƒÖc dane magazynowe, mog≈Çbym powiedzieƒá wiƒôcej o "${query}". Mam dostƒôp do bazy danych systemu MRP, ale potrzebujƒô klucza API OpenAI do bardziej zaawansowanych analiz.`,
    `Aby udzieliƒá precyzyjnej odpowiedzi na temat "${query}", korzystam z danych w bazie systemu MRP. Dla lepszych wynik√≥w zalecam konfiguracjƒô klucza API OpenAI.`,
    `System po≈ÇƒÖczony z bazƒÖ danych mo≈ºe analizowaƒá "${query}", ale bardziej zaawansowane funkcje wymagajƒÖ klucza API OpenAI.`
  ];
  
  return mockResponses[Math.floor(Math.random() * mockResponses.length)];
};

/**
 * Pobierz historiƒô konwersacji dla danego u≈ºytkownika
 * @param {string} userId - ID u≈ºytkownika
 * @param {number} limitCount - Limit liczby konwersacji do pobrania
 * @returns {Promise<Array>} - Lista konwersacji
 */
export const getUserConversations = async (userId, limitCount = 10) => {
  try {
    // Korzystamy z kolekcji aiConversations
    const conversationsRef = collection(db, 'aiConversations');
    
    // OPTYMALIZACJA: Zmniejszamy rozmiar danych, dodajƒÖc limity
    // i wybierajƒÖc tylko te pola, kt√≥re sƒÖ niezbƒôdne
    const q = query(
      conversationsRef,
      where('userId', '==', userId),
      orderBy('updatedAt', 'desc'),
      limit(limitCount)
    );
    
    // Wykonujemy tylko jedno zapytanie zamiast wielokrotnych zapyta≈Ñ
    const querySnapshot = await getDocs(q);
    
    // Mapujemy wyniki, ograniczajƒÖc ilo≈õƒá przetwarzanych danych
    return querySnapshot.docs.map(doc => ({
      id: doc.id,
      title: doc.data().title || 'Nowa konwersacja',
      updatedAt: doc.data().updatedAt,
      messageCount: doc.data().messageCount || 0
      // Nie pobieramy pe≈Çnych tre≈õci wiadomo≈õci, tylko niezbƒôdne metadane
    }));
  } catch (error) {
    console.error('B≈ÇƒÖd podczas pobierania konwersacji u≈ºytkownika:', error);
    throw error;
  }
};

/**
 * Pobierz wiadomo≈õci dla danej konwersacji
 * @param {string} conversationId - ID konwersacji
 * @returns {Promise<Array>} - Lista wiadomo≈õci
 */
export const getConversationMessages = async (conversationId) => {
  try {
    const messagesRef = collection(db, 'aiConversations', conversationId, 'messages');
    const q = query(messagesRef, orderBy('timestamp', 'asc'));
    
    const querySnapshot = await getDocs(q);
    return querySnapshot.docs.map(doc => ({
      id: doc.id,
      ...doc.data()
    }));
  } catch (error) {
    console.error('B≈ÇƒÖd podczas pobierania wiadomo≈õci konwersacji:', error);
    throw error;
  }
};

/**
 * Utw√≥rz nowƒÖ konwersacjƒô
 * @param {string} userId - ID u≈ºytkownika
 * @param {string} title - Tytu≈Ç konwersacji
 * @returns {Promise<string>} - ID utworzonej konwersacji
 */
export const createConversation = async (userId, title = 'Nowa konwersacja') => {
  try {
    const conversationsRef = collection(db, 'aiConversations');
    const docRef = await addDoc(conversationsRef, {
      userId,
      title,
      createdAt: serverTimestamp(),
      updatedAt: serverTimestamp(),
      messageCount: 0
    });
    
    return docRef.id;
  } catch (error) {
    console.error('B≈ÇƒÖd podczas tworzenia nowej konwersacji:', error);
    throw error;
  }
};

/**
 * Przesy≈Ça za≈ÇƒÖcznik do Firebase Storage
 * @param {File} file - Plik do przes≈Çania
 * @param {string} userId - ID u≈ºytkownika
 * @param {string} conversationId - ID konwersacji
 * @returns {Promise<Object>} - Informacje o przes≈Çanym pliku
 */
export const uploadAttachment = async (file, userId, conversationId) => {
  try {
    if (!file || !userId || !conversationId) {
      throw new Error('Brak wymaganych parametr√≥w');
    }

    // Sprawd≈∫ rozmiar pliku (maksymalnie 10 MB)
    const fileSizeInMB = file.size / (1024 * 1024);
    if (fileSizeInMB > 10) {
      throw new Error(`Plik jest zbyt du≈ºy (${fileSizeInMB.toFixed(2)} MB). Maksymalny rozmiar to 10 MB.`);
    }

    // Sprawd≈∫ typ pliku - dozwolone sƒÖ pliki tekstowe, obrazy i dokumenty
    const allowedTypes = [
      'text/plain',
      'text/csv',
      'application/json',
      'application/pdf',
      'application/msword',
      'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
      'application/vnd.ms-excel',
      'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
      'image/jpeg',
      'image/png',
      'image/gif',
      'image/webp'
    ];

    if (!allowedTypes.includes(file.type)) {
      throw new Error(`Nieobs≈Çugiwany typ pliku: ${file.type}. Dozwolone sƒÖ pliki tekstowe, dokumenty i obrazy.`);
    }

    // Tworzymy ≈õcie≈ºkƒô do pliku w Firebase Storage
    const timestamp = new Date().getTime();
    const fileExtension = file.name.split('.').pop();
    const sanitizedFileName = file.name.replace(/[^a-zA-Z0-9.-]/g, '_');
    const fileName = `${timestamp}_${sanitizedFileName}`;
    const storagePath = `ai-attachments/${userId}/${conversationId}/${fileName}`;

    // Przesy≈Çamy plik do Firebase Storage
    const fileRef = ref(storage, storagePath);
    await uploadBytes(fileRef, file);

    // Pobieramy URL do pobrania pliku
    const downloadURL = await getDownloadURL(fileRef);

    return {
      fileName: file.name,
      storagePath,
      downloadURL,
      contentType: file.type,
      size: file.size,
      uploadedAt: new Date().toISOString()
    };
  } catch (error) {
    console.error('B≈ÇƒÖd podczas przesy≈Çania za≈ÇƒÖcznika:', error);
    throw error;
  }
};

/**
 * Usuwa za≈ÇƒÖcznik z Firebase Storage
 * @param {string} storagePath - ≈öcie≈ºka do pliku w Storage
 * @returns {Promise<void>}
 */
export const deleteAttachment = async (storagePath) => {
  try {
    const fileRef = ref(storage, storagePath);
    await deleteObject(fileRef);
  } catch (error) {
    console.error('B≈ÇƒÖd podczas usuwania za≈ÇƒÖcznika:', error);
    throw error;
  }
};

/**
 * Pobiera zawarto≈õƒá pliku tekstowego z URL
 * @param {string} downloadURL - URL do pobrania pliku
 * @param {string} contentType - Typ zawarto≈õci pliku
 * @returns {Promise<string>} - Zawarto≈õƒá pliku jako tekst
 */
export const getFileContent = async (downloadURL, contentType) => {
  try {
    const response = await fetch(downloadURL);
    if (!response.ok) {
      throw new Error(`B≈ÇƒÖd podczas pobierania pliku: ${response.status}`);
    }

    // Dla plik√≥w tekstowych zwracamy bezpo≈õrednio tekst
    if (contentType.startsWith('text/') || contentType === 'application/json') {
      return await response.text();
    }

    // Dla innych typ√≥w plik√≥w zwracamy informacje o pliku
    return `[Za≈ÇƒÖcznik: ${contentType}, rozmiar: ${response.headers.get('content-length') || 'nieznany'}]`;
  } catch (error) {
    console.error('B≈ÇƒÖd podczas pobierania zawarto≈õci pliku:', error);
    return `[B≈ÇƒÖd podczas odczytywania pliku: ${error.message}]`;
  }
};

/**
 * Dodaj wiadomo≈õƒá do konwersacji z mo≈ºliwo≈õciƒÖ za≈ÇƒÖczenia plik√≥w
 * @param {string} conversationId - ID konwersacji
 * @param {string} role - Rola nadawcy ('user' lub 'assistant')
 * @param {string} content - Tre≈õƒá wiadomo≈õci
 * @param {Array} attachments - Lista za≈ÇƒÖcznik√≥w (opcjonalne)
 * @returns {Promise<string>} - ID dodanej wiadomo≈õci
 */
export const addMessageToConversation = async (conversationId, role, content, attachments = []) => {
  try {
    // Dodanie wiadomo≈õci
    const messagesRef = collection(db, 'aiConversations', conversationId, 'messages');
    const timestamp = new Date().toISOString();
    
    const messageData = {
      role,
      content,
      timestamp
    };

    // Dodaj za≈ÇƒÖczniki je≈õli sƒÖ dostƒôpne
    if (attachments && attachments.length > 0) {
      messageData.attachments = attachments;
    }
    
    const docRef = await addDoc(messagesRef, messageData);
    
    // Aktualizacja licznika wiadomo≈õci i daty aktualizacji konwersacji
    const conversationRef = doc(db, 'aiConversations', conversationId);
    const conversationDoc = await getDoc(conversationRef);
    
    if (conversationDoc.exists()) {
      await updateDoc(conversationRef, {
        messageCount: (conversationDoc.data().messageCount || 0) + 1,
        updatedAt: serverTimestamp(),
        // Aktualizujemy tytu≈Ç konwersacji na podstawie pierwszej wiadomo≈õci u≈ºytkownika
        ...(role === 'user' && conversationDoc.data().messageCount === 0 ? 
          { title: content.substring(0, 50) + (content.length > 50 ? '...' : '') } 
          : {})
      });
    }
    
    return docRef.id;
  } catch (error) {
    console.error('B≈ÇƒÖd podczas dodawania wiadomo≈õci do konwersacji:', error);
    throw error;
  }
};

/**
 * Obs≈Çugiwane typy MIME dla Gemini Vision
 */
const VISION_SUPPORTED_TYPES = [
  'image/jpeg',
  'image/png', 
  'image/gif',
  'image/webp',
  'application/pdf'
];

/**
 * WyciƒÖga za≈ÇƒÖczniki obrazowe/PDF i konwertuje na format dla Gemini Vision
 * @param {Array} attachments - Lista za≈ÇƒÖcznik√≥w z Firebase Storage
 * @returns {Promise<Array>} - Lista za≈ÇƒÖcznik√≥w w formacie [{mimeType, base64Data}]
 */
const extractMediaAttachments = async (attachments) => {
  const mediaAttachments = [];
  
  if (!attachments || attachments.length === 0) {
    return mediaAttachments;
  }
  
  for (const attachment of attachments) {
    try {
      // Sprawd≈∫ czy to obs≈Çugiwany typ
      const mimeType = attachment.contentType || attachment.type;
      if (!VISION_SUPPORTED_TYPES.includes(mimeType)) {
        console.log(`[extractMediaAttachments] ‚è≠Ô∏è Pomijam nieobs≈Çugiwany typ: ${mimeType}`);
        continue;
      }
      
      // Pobierz plik jako blob
      console.log(`[extractMediaAttachments] üì• Pobieram: ${attachment.fileName} (${mimeType})`);
      const response = await fetch(attachment.downloadURL);
      
      if (!response.ok) {
        console.error(`[extractMediaAttachments] ‚ùå B≈ÇƒÖd pobierania: ${response.status}`);
        continue;
      }
      
      const blob = await response.blob();
      
      // Sprawd≈∫ rozmiar (max 20MB dla inline_data)
      const maxSize = 20 * 1024 * 1024; // 20MB
      if (blob.size > maxSize) {
        console.warn(`[extractMediaAttachments] ‚ö†Ô∏è Plik za du≈ºy: ${(blob.size / 1024 / 1024).toFixed(2)}MB > 20MB`);
        continue;
      }
      
      // Konwertuj na base64
      const base64Data = await blobToBase64(blob);
      
      mediaAttachments.push({
        mimeType: mimeType,
        base64Data: base64Data,
        fileName: attachment.fileName,
        size: blob.size
      });
      
      console.log(`[extractMediaAttachments] ‚úÖ Dodano: ${attachment.fileName} (${(blob.size / 1024).toFixed(1)}KB)`);
      
    } catch (error) {
      console.error(`[extractMediaAttachments] ‚ùå B≈ÇƒÖd przetwarzania za≈ÇƒÖcznika:`, error);
    }
  }
  
  return mediaAttachments;
};

/**
 * Konwertuje Blob na base64 (bez prefixu data:...)
 * @param {Blob} blob - Blob do konwersji
 * @returns {Promise<string>} - Base64 string bez prefixu
 */
const blobToBase64 = (blob) => {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onloadend = () => {
      // Usu≈Ñ prefix "data:...;base64,"
      const base64 = reader.result.split(',')[1];
      resolve(base64);
    };
    reader.onerror = reject;
    reader.readAsDataURL(blob);
  });
};

/**
 * Funkcja przetwarzajƒÖca zapytanie u≈ºytkownika i zwracajƒÖca odpowied≈∫ asystenta
 * U≈ºywa GPT-4o poprzez API OpenAI, wzbogacone o dane z bazy danych
 * @param {string} query - Zapytanie u≈ºytkownika
 * @param {Array} context - Kontekst konwersacji (poprzednie wiadomo≈õci)
 * @param {string} userId - ID u≈ºytkownika
 * @param {Array} attachments - Lista za≈ÇƒÖcznik√≥w (opcjonalne)
 * @returns {Promise<string>} - Odpowied≈∫ asystenta
 */
export const processAIQuery = async (query, context = [], userId, attachments = [], onChunk = null) => {
  console.log('[processAIQuery] üöÄ Rozpoczynam przetwarzanie zapytania:', query);
  
  // üî• STREAMING: Je≈õli mamy callback, loguj to
  if (onChunk) {
    console.log('[processAIQuery] Streaming w≈ÇƒÖczony - chunki bƒôdƒÖ przekazywane w czasie rzeczywistym');
  }
  
  try {
    // ‚ú® SYSTEM: Gemini Query Orchestrator - ZAWSZE u≈ºywa narzƒôdzi do pobierania danych
    const hasAttachments = attachments && attachments.length > 0;
    
    // üñºÔ∏è VISION MODE: Je≈õli sƒÖ za≈ÇƒÖczniki obrazowe/PDF
    if (hasAttachments) {
      const mediaAttachments = await extractMediaAttachments(attachments);
      
      if (mediaAttachments.length > 0) {
        console.log(`[processAIQuery] üñºÔ∏è Wykryto ${mediaAttachments.length} za≈ÇƒÖcznik(√≥w) multimedialnych - u≈ºywam Gemini Vision`);
        
        try {
          const apiKey = await getGeminiApiKey(userId);
          
          if (!apiKey) {
            return "‚ùå Nie znaleziono klucza API Gemini. Proszƒô skonfigurowaƒá klucz w ustawieniach systemu.\n\n" +
                   "üí° Uzyskaj klucz API na: https://aistudio.google.com/app/apikey";
          }
          
          // U≈ºyj Gemini z Vision API + narzƒôdzia
          const orchestratorResult = await GeminiQueryOrchestrator.processQuery(
            query, 
            apiKey, 
            context,
            {
              mediaAttachments: mediaAttachments,
              enableThinking: true,
              userId
            }
          );
          
          if (orchestratorResult.success) {
            console.log(`[processAIQuery] ‚úÖ Gemini Vision odpowiedzia≈Ç: ${orchestratorResult.response?.substring(0, 100)}...`);
            
            let response = orchestratorResult.response;
            const estimatedCost = GeminiQueryOrchestrator.estimateCost(orchestratorResult.tokensUsed, orchestratorResult.model);
            response += `\n\n_Koszt: ~$${estimatedCost.toFixed(4)}_`;
            
            return response;
          } else {
            console.error('[processAIQuery] ‚ùå Gemini Vision nie zdo≈Ça≈Ç przetworzyƒá:', orchestratorResult.error);
            return `‚ùå Nie uda≈Ço siƒô przeanalizowaƒá dokumentu: ${orchestratorResult.error}`;
          }
        } catch (visionError) {
          console.error('[processAIQuery] ‚ùå B≈ÇƒÖd w trybie Vision:', visionError);
          return `‚ùå WystƒÖpi≈Ç b≈ÇƒÖd podczas analizy dokumentu: ${visionError.message}`;
        }
      } else {
        console.log('[processAIQuery] üìé Za≈ÇƒÖczniki nie sƒÖ obrazami/PDF - u≈ºywam standardowego systemu');
        // Kontynuuj do standardowego systemu poni≈ºej
      }
    }
    
    // üéØ STANDARDOWY TRYB: Gemini Query Orchestrator z narzƒôdziami (ZAWSZE!)
    console.log('[processAIQuery] üéØ U≈ºywam Gemini Query Orchestrator - Gemini zdecyduje jakie dane pobraƒá');
    
    try {
      const apiKey = await getGeminiApiKey(userId);
      
      if (!apiKey) {
        return "‚ùå Nie znaleziono klucza API Gemini. Proszƒô skonfigurowaƒá klucz w ustawieniach systemu.\n\n" +
               "üí° Uzyskaj klucz API na: https://aistudio.google.com/app/apikey";
      }
      
      // ZAWSZE u≈ºywaj orchestratora z narzƒôdziami - NIE MA trybu konwersacyjnego!
      const orchestratorResult = await GeminiQueryOrchestrator.processQuery(
        query, 
        apiKey, 
        context,
        {
          enableThinking: true,
          userId
        }
      );
      
      if (orchestratorResult.success) {
        console.log(`[processAIQuery] ‚úÖ Gemini Orchestrator zako≈Ñczy≈Ç w ${orchestratorResult.processingTime.toFixed(2)}ms`);
        console.log(`[processAIQuery] ü§ñ U≈ºyty model: ${orchestratorResult.model}`);
        console.log(`[processAIQuery] üìä Wykonano ${orchestratorResult.executedTools.length} targetowanych zapyta≈Ñ do bazy`);
        console.log(`[processAIQuery] üìù Otrzymano odpowied≈∫ (d≈Çugo≈õƒá: ${orchestratorResult.response?.length} znak√≥w):`, orchestratorResult.response?.substring(0, 200) + '...');
        
        let response = orchestratorResult.response;
        
        if (orchestratorResult.executedTools.length > 0) {
          const estimatedCost = GeminiQueryOrchestrator.estimateCost(orchestratorResult.tokensUsed, orchestratorResult.model);
          response += `\n\n_Koszt: ~$${estimatedCost.toFixed(4)}_`;
        }
        
        console.log(`[processAIQuery] üéÅ Zwracam odpowied≈∫ (d≈Çugo≈õƒá: ${response?.length} znak√≥w):`, response?.substring(0, 200) + '...');
        
        return response;
      } else {
        console.error('[processAIQuery] ‚ùå Gemini Orchestrator nie zdo≈Ça≈Ç przetworzyƒá zapytania');
        console.error('[processAIQuery] B≈ÇƒÖd:', orchestratorResult.error);
        
        return `‚ùå **Nie uda≈Ço siƒô przetworzyƒá zapytania**\n\n` +
               `Szczeg√≥≈Çy: ${orchestratorResult.error}\n\n` +
               `üí° Spr√≥buj:\n` +
               `‚Ä¢ Upro≈õƒá zapytanie\n` +
               `‚Ä¢ Zmniejsz liczbƒô ≈ºƒÖdanych element√≥w\n` +
               `‚Ä¢ Podziel zapytanie na mniejsze czƒô≈õci\n` +
               `‚Ä¢ Sprawd≈∫ czy klucz API Gemini jest poprawny`;
      }
      
    } catch (orchestratorError) {
      console.error('[processAIQuery] ‚ùå B≈ÇƒÖd w Gemini Orchestrator:', orchestratorError);
      
      return `‚ùå **WystƒÖpi≈Ç b≈ÇƒÖd podczas przetwarzania zapytania**\n\n` +
             `Szczeg√≥≈Çy: ${orchestratorError.message}\n\n` +
             `üí° Spr√≥buj ponownie lub skontaktuj siƒô z administratorem.\n` +
             `Je≈õli problem dotyczy klucza API, sprawd≈∫ konfiguracjƒô w ustawieniach.`;
    }
  } catch (error) {
    console.error('[processAIQuery] ‚ùå B≈ÇƒÖd podczas wyboru systemu:', error);
    return `‚ùå **WystƒÖpi≈Ç nieoczekiwany b≈ÇƒÖd**\n\n` +
           `Szczeg√≥≈Çy: ${error.message}\n\n` +
           `üí° Spr√≥buj ponownie lub skontaktuj siƒô z administratorem.`;
  }
  
  // STANDARDOWY SYSTEM - TYLKO dla za≈ÇƒÖcznik√≥w
  console.log('[processAIQuery] üìö U≈ºywam standardowego systemu z pe≈Çnym kontekstem danych (za≈ÇƒÖczniki)');
  
  // Limit czasu na pobranie danych (w milisekundach) - zoptymalizowany
  const DATA_FETCH_TIMEOUT = 8000;
  
  // ≈πr√≥d≈Ça danych - bufor do ≈õledzenia czy dane zosta≈Çy pobrane
  const dataSources = {
    'businessData': { ready: false, data: null },
    'apiKey': { ready: false, data: null }
  };
  
  try {
    // Wystartuj odliczanie dla limitu czasu - gdy czas up≈Çynie, u≈ºyjemy dostƒôpnych danych
    const timeoutPromise = new Promise(resolve => {
      setTimeout(() => {
        console.log('Up≈ÇynƒÖ≈Ç limit czasu na pobranie danych, generujƒô odpowied≈∫ z dostƒôpnymi danymi');
        resolve();
      }, DATA_FETCH_TIMEOUT);
    });
    
    // R√≥wnoleg≈Çe pobieranie danych
    const businessDataPromise = Promise.resolve().then(async () => {
      try {
        // Przekazujemy zapytanie u≈ºytkownika do funkcji pobierajƒÖcej dane
        const data = await prepareBusinessDataForAI(query);
        dataSources.businessData = { ready: true, data };
        console.log('Dane biznesowe zosta≈Çy pomy≈õlnie pobrane z pe≈Çnymi szczeg√≥≈Çami');
      } catch (error) {
        console.error('B≈ÇƒÖd podczas pobierania danych biznesowych:', error);
        dataSources.businessData = { ready: true, data: null };
      }
    });
    
    const apiKeyPromise = Promise.resolve().then(async () => {
      try {
        const apiKey = await getOpenAIApiKey(userId);
        dataSources.apiKey = { ready: true, data: apiKey };
      } catch (error) {
        console.error('B≈ÇƒÖd podczas pobierania klucza API:', error);
        dataSources.apiKey = { ready: true, data: null };
      }
    });
    
    // Poczekaj na wszystkie procesy lub na up≈Çyw limitu czasu
    await Promise.race([
      Promise.all([businessDataPromise, apiKeyPromise]),
      timeoutPromise
    ]);
    
    // Pobierz dostƒôpne dane
    const businessData = dataSources.businessData.data;
    const apiKey = dataSources.apiKey.data;
    
    // Sprawd≈∫ czy nadal trwa pobieranie danych
    const isDataFetchingActive = !dataSources.businessData.ready || 
                                 !dataSources.apiKey.ready;
    
    // Je≈õli dane sƒÖ nadal pobierane, a nie mamy klucza API lub musimy go u≈ºyƒá
    if (isDataFetchingActive && (!apiKey || query.toLowerCase().includes('dane') || query.toLowerCase().includes('system'))) {
      // Wygeneruj tymczasowƒÖ odpowied≈∫
      return `Pracujƒô nad szczeg√≥≈ÇowƒÖ analizƒÖ danych dla Twojego zapytania "${query}". Pobieram wszystkie dostƒôpne dane z systemu MRP, aby zapewniƒá pe≈Çne i dok≈Çadne informacje. To mo≈ºe potrwaƒá chwilƒô ze wzglƒôdu na du≈ºƒÖ ilo≈õƒá danych. Proszƒô o cierpliwo≈õƒá.`;
    }
    
    // Je≈õli nie ma klucza API, u≈ºywamy funkcji z danymi lokalnymi
    if (!apiKey) {
      console.log('Brak klucza API - generujƒô odpowied≈∫ lokalnie');
      return getMockResponse(query, businessData);
    }
    
    // Przygotowanie tre≈õci zapytania z za≈ÇƒÖcznikami
    let queryWithAttachments = query;
    
    if (attachments && attachments.length > 0) {
      queryWithAttachments += '\n\n--- Za≈ÇƒÖczone pliki ---\n';
      
      for (const attachment of attachments) {
        try {
          queryWithAttachments += `\nPlik: ${attachment.fileName} (${attachment.contentType})\n`;
          
          // Je≈õli to plik tekstowy, pobierz jego zawarto≈õƒá
          if (attachment.contentType.startsWith('text/') || attachment.contentType === 'application/json') {
            const fileContent = await getFileContent(attachment.downloadURL, attachment.contentType);
            queryWithAttachments += `Zawarto≈õƒá:\n${fileContent}\n`;
          } else if (attachment.contentType.startsWith('image/')) {
            queryWithAttachments += `[Obraz: ${attachment.fileName}]\n`;
          } else {
            queryWithAttachments += `[Dokument: ${attachment.fileName}]\n`;
          }
        } catch (error) {
          console.error('B≈ÇƒÖd podczas przetwarzania za≈ÇƒÖcznika:', error);
          queryWithAttachments += `[B≈ÇƒÖd podczas odczytywania pliku: ${attachment.fileName}]\n`;
        }
      }
    }
    
    // Przygotowanie wiadomo≈õci do wys≈Çania z optymalizacjami
    const allMessages = [...context, { role: 'user', content: queryWithAttachments }];
    
    // Okre≈õl poziom z≈Ço≈ºono≈õci zapytania dla optymalizacji
    const complexity = queryWithAttachments.length > 100 ? 'complex' : 
                      queryWithAttachments.length > 50 ? 'medium' : 'simple';
    
    const formattedMessages = formatMessagesForOpenAI(allMessages, businessData, {
      enableOptimization: true,
      modelType: complexity
    });
    
    // üî• NOWA OPTYMALIZACJA: Sprawd≈∫ rozmiar danych przed wys≈Çaniem
    const messagesSize = JSON.stringify(formattedMessages).length;
    const estimatedTokens = Math.ceil(messagesSize / 3); // ~3 znaki = 1 token dla PL
    const GPT5_INPUT_LIMIT = 272000; // Limit INPUT dla GPT-5
    
    console.log(`[TOKEN CHECK] üìä Rozmiar danych:`, {
      charactersCount: messagesSize,
      estimatedTokens: estimatedTokens,
      limit: GPT5_INPUT_LIMIT,
      utilizationPercent: ((estimatedTokens / GPT5_INPUT_LIMIT) * 100).toFixed(1) + '%',
      withinLimit: estimatedTokens <= GPT5_INPUT_LIMIT
    });
    
    // Ostrze≈ºenie je≈õli zbli≈ºamy siƒô do limitu
    if (estimatedTokens > GPT5_INPUT_LIMIT * 0.9) {
      console.warn(`‚ö†Ô∏è [TOKEN CHECK] UWAGA: U≈ºywasz ${((estimatedTokens / GPT5_INPUT_LIMIT) * 100).toFixed(1)}% limitu token√≥w!`);
    }
    
    if (estimatedTokens > GPT5_INPUT_LIMIT) {
      console.error(`‚ùå [TOKEN CHECK] B≈ÅƒÑD: Przekroczono limit token√≥w! ${estimatedTokens} > ${GPT5_INPUT_LIMIT}`);
      throw new Error(`Zapytanie jest zbyt du≈ºe (${estimatedTokens} token√≥w). Limit to ${GPT5_INPUT_LIMIT} token√≥w. Spr√≥buj zadaƒá bardziej konkretne pytanie.`);
    }
    
    console.log('Wysy≈Çam zapytanie do API OpenAI z pe≈Çnymi danymi z Firebase...');
    
    // Wywo≈Çanie API OpenAI z optymalizacjami
    try {
      const apiCallStartTime = performance.now();
      const response = await callOpenAIAPI(apiKey, formattedMessages, {
        complexity,
        optimizationOptions: {
          prioritizeSpeed: complexity === 'simple',
          prioritizeCost: true,
          enableCache: true
        }
      }, onChunk);  // üî• STREAMING: Przekazuj callback do API
      const apiCallEndTime = performance.now();
      const responseTime = apiCallEndTime - apiCallStartTime;
      
      console.log('Otrzymano odpowied≈∫ z API OpenAI');
      
      if (!response || response.trim() === '') {
        console.error('API OpenAI zwr√≥ci≈Ço pustƒÖ odpowied≈∫');
        return getMockResponse(query, businessData); // Fallback do lokalnej odpowiedzi
      }
      
      return response;
    } catch (apiError) {
      console.error('B≈ÇƒÖd podczas komunikacji z API OpenAI:', apiError);
      
      // Szczeg√≥≈Çowa obs≈Çuga r√≥≈ºnych rodzaj√≥w b≈Çƒôd√≥w
      if (apiError.message.includes('Przekroczono limit zapyta≈Ñ')) {
        return `üòû Przekroczono limit zapyta≈Ñ do API OpenAI. Spr√≥buj ponownie za kilka minut lub sprawd≈∫ ustawienia swojego konta OpenAI (https://platform.openai.com/account/limits).`;
      } else if (apiError.message.includes('Przekroczono przydzia≈Ç') || apiError.message.includes('quota') || apiError.message.includes('billing')) {
        return `‚ö†Ô∏è Przekroczono limit dostƒôpnych ≈õrodk√≥w na koncie OpenAI. Aby kontynuowaƒá korzystanie z asystenta AI, sprawd≈∫ sw√≥j plan i dane rozliczeniowe na stronie: https://platform.openai.com/account/billing`;
      } else if (apiError.message.includes('API')) {
        return `‚ùå WystƒÖpi≈Ç b≈ÇƒÖd podczas komunikacji z API OpenAI: ${apiError.message}. Sprawd≈∫ sw√≥j klucz API lub spr√≥buj ponownie p√≥≈∫niej.`;
      }
      
      // Fallback do mocka w przypadku innego b≈Çƒôdu
      return getMockResponse(query, businessData);
    }
  } catch (error) {
    console.error('B≈ÇƒÖd podczas przetwarzania zapytania przez AI:', error);
    console.error('Szczeg√≥≈Çy b≈Çƒôdu:', error.message, error.stack);
    
    // Generowanie lokalnej odpowiedzi z informacjƒÖ o b≈Çƒôdzie
    return `Przepraszam, ale napotka≈Çem problem podczas przetwarzania zapytania. Spr√≥buj ponownie za chwilƒô lub skontaktuj siƒô z administratorem systemu. (B≈ÇƒÖd: ${error.message || 'Nieznany b≈ÇƒÖd'})`;
  }
};

/**
 * Usu≈Ñ konwersacjƒô
 * @param {string} conversationId - ID konwersacji do usuniƒôcia
 * @returns {Promise<void>}
 */
export const deleteConversation = async (conversationId) => {
  try {
    // W pe≈Çnej implementacji nale≈ºa≈Çoby r√≥wnie≈º usunƒÖƒá wszystkie wiadomo≈õci w podkolekcji
    const conversationRef = doc(db, 'aiConversations', conversationId);
    await deleteDoc(conversationRef);
  } catch (error) {
    console.error('B≈ÇƒÖd podczas usuwania konwersacji:', error);
    throw error;
  }
}; 