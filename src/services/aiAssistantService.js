import { db, storage } from './firebase/config';
import { 
  collection, 
  addDoc, 
  getDocs, 
  getDoc, 
  updateDoc, 
  doc, 
  query, 
  where, 
  orderBy, 
  serverTimestamp,
  limit,
  deleteDoc,
  setDoc
} from 'firebase/firestore';
import { ref, uploadBytes, getDownloadURL, deleteObject } from 'firebase/storage';
import { 
  prepareBusinessDataForAI, 
  getMRPSystemSummary, 
  getInventoryItems, 
  getCustomerOrders, 
  getProductionTasks, 
  getSuppliers,
  getRecipes,
  getPurchaseOrders
} from './aiDataService';
import { getSystemSettings, getGlobalOpenAIApiKey } from './settingsService';
import { AIAssistantV2 } from './ai/AIAssistantV2.js';
import { AIQueryOrchestrator } from './ai/AIQueryOrchestrator.js';
import { SmartModelSelector } from './ai/optimization/SmartModelSelector.js';
import { ContextOptimizer } from './ai/optimization/ContextOptimizer.js';
import { GPTResponseCache } from './ai/optimization/GPTResponseCache.js';

// Deklaracja funkcji getMockResponse przed jej uÅ¼yciem (hoisting)
let getMockResponse;

// Maksymalna liczba wiadomoÅ›ci w kontekÅ›cie
const MAX_CONTEXT_MESSAGES = 15;

/**
 * Pobierz klucz API OpenAI zapisany w bazie danych Firebase
 * @param {string} userId - ID uÅ¼ytkownika
 * @returns {Promise<string|null>} - Klucz API OpenAI lub null jeÅ›li nie znaleziono
 */
export const getOpenAIApiKey = async (userId) => {
  try {
    // Najpierw sprawdzamy ustawienia systemowe
    const systemSettings = await getSystemSettings();
    
    // JeÅ›li wÅ‚Ä…czona jest opcja globalnego klucza API, pobieramy go
    if (systemSettings.useGlobalApiKey) {
      const globalApiKey = await getGlobalOpenAIApiKey();
      if (globalApiKey) {
        return globalApiKey;
      }
    }
    
    // JeÅ›li nie ma globalnego klucza lub nie jest uÅ¼ywany, prÃ³bujemy pobraÄ‡ klucz uÅ¼ytkownika
    const apiKeyRef = doc(db, 'settings', 'openai', 'users', userId);
    const apiKeyDoc = await getDoc(apiKeyRef);
    
    if (apiKeyDoc.exists() && apiKeyDoc.data().apiKey) {
      return apiKeyDoc.data().apiKey;
    }
    
    return null;
  } catch (error) {
    console.error('BÅ‚Ä…d podczas pobierania klucza API OpenAI:', error);
    throw error;
  }
};

/**
 * Zapisz klucz API OpenAI w bazie danych Firebase
 * @param {string} userId - ID uÅ¼ytkownika
 * @param {string} apiKey - Klucz API OpenAI
 * @returns {Promise<void>}
 */
export const saveOpenAIApiKey = async (userId, apiKey) => {
  try {
    const apiKeyRef = doc(db, 'settings', 'openai', 'users', userId);
    await setDoc(apiKeyRef, {
      apiKey,
      updatedAt: serverTimestamp()
    });
  } catch (error) {
    console.error('BÅ‚Ä…d podczas zapisywania klucza API OpenAI:', error);
    throw error;
  }
};

/**
 * WysyÅ‚a zapytanie do API OpenAI z optymalizacjami
 * @param {string} apiKey - Klucz API OpenAI
 * @param {Array} messages - WiadomoÅ›ci do wysÅ‚ania do API
 * @param {Object} options - Opcje optymalizacji
 * @returns {Promise<string>} - OdpowiedÅº asystenta
 */
export const callOpenAIAPI = async (apiKey, messages, options = {}, onChunk = null) => {
  try {
    // WyciÄ…gnij zapytanie uÅ¼ytkownika dla optymalizacji
    const userQuery = messages[messages.length - 1]?.content || '';
    const contextSize = JSON.stringify(messages).length;
    
    // NOWA OPTYMALIZACJA: Inteligentny wybÃ³r modelu
    const modelConfig = SmartModelSelector.selectOptimalModel(
      userQuery, 
      contextSize, 
      options.complexity || 'medium',
      options.optimizationOptions || {}
    );

    console.log(`[callOpenAIAPI] UÅ¼yjÄ™ modelu ${modelConfig.model} (szacowany koszt: $${modelConfig.estimatedCost.toFixed(4)})`);

    // NOWA OPTYMALIZACJA: Cache dla odpowiedzi
    const contextHash = GPTResponseCache.generateContextHash(messages);
    const cacheOptions = {
      enableCache: true,
      estimatedCost: modelConfig.estimatedCost,
      cacheDuration: options.cacheDuration || GPTResponseCache.CACHE_DURATION
    };

    const apiStartTime = performance.now();
    
    const cachedResponse = await GPTResponseCache.getCachedOrFetch(
      userQuery,
      contextHash,
      async () => {
        // Wykonanie rzeczywistego zapytania API
        // GPT-5 ma inne wymagania API niÅ¼ poprzednie modele
        const isGPT5 = modelConfig.model === 'gpt-5';
        
        const requestBody = {
          model: modelConfig.model,
          messages,
          stream: true  // OPTYMALIZACJA: WÅ‚Ä…czono streaming dla natychmiastowej odpowiedzi
        };
        
        // GPT-5 wymaga innych parametrÃ³w:
        if (isGPT5) {
          // GPT-5 uÅ¼ywa max_completion_tokens i nie wspiera niestandardowego temperature
          // WAÅ»NE: max_completion_tokens obejmuje reasoning_tokens + output_tokens
          // OPTYMALIZACJA: Zmniejszono z 20000 do 4000 dla szybszych odpowiedzi
          requestBody.max_completion_tokens = 4000;  // ÅÄ…czny limit (reasoning + output) - zoptymalizowano
          
          // GPT-5 wymaga nowych parametrÃ³w kontrolujÄ…cych generowanie odpowiedzi
          // OPTYMALIZACJA: Ustawiono 'low' dla szybszego czasu odpowiedzi
          requestBody.reasoning_effort = 'low';     // low, medium, high - kontroluje czas rozumowania (zoptymalizowano)
          requestBody.verbosity = 'medium';         // low, medium, high - kontroluje dÅ‚ugoÅ›Ä‡ odpowiedzi (zoptymalizowano)
          
          console.log('[GPT-5] Parametry zapytania:', {
            max_completion_tokens: requestBody.max_completion_tokens,
            reasoning_effort: requestBody.reasoning_effort,
            verbosity: requestBody.verbosity,
            note: 'max_completion_tokens includes reasoning_tokens + output_tokens'
          });
          
          // GPT-5 przyjmuje tylko domyÅ›lnÄ… wartoÅ›Ä‡ temperature (1)
          // Nie dodajemy parametru temperature dla GPT-5
        } else {
          // Inne modele uÅ¼ywajÄ… standardowych parametrÃ³w
          requestBody.max_tokens = modelConfig.maxTokens;
          requestBody.temperature = modelConfig.temperature;
        }
        
        const response = await fetch('https://api.openai.com/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${apiKey}`
          },
          body: JSON.stringify(requestBody)
        });

        if (!response.ok) {
          const errorData = await response.json();
          const errorMessage = errorData.error?.message || 'BÅ‚Ä…d podczas komunikacji z API OpenAI';
          
          console.error('[API Error] Status:', response.status, 'Message:', errorMessage);
          console.error('[API Error] Full error data:', errorData);
          
          // Sprawdzamy, czy error dotyczy limitu zapytaÅ„ lub pobierania
          if (response.status === 429) {
            throw new Error(`Przekroczono limit zapytaÅ„ do API OpenAI: ${errorMessage}`);
          } else if (errorMessage.includes('quota')) {
            throw new Error(`Przekroczono przydziaÅ‚ API OpenAI: ${errorMessage}`);
          } else {
            throw new Error(errorMessage);
          }
        }
        
        // STREAMING: ObsÅ‚uga odpowiedzi strumieniowej
        console.log('[STREAMING] Rozpoczynam odczyt odpowiedzi strumieniowej...');
        const reader = response.body.getReader();
        const decoder = new TextDecoder();
        let fullResponse = '';
        let buffer = '';
        let tokenStats = null;
        
        try {
          while (true) {
            const { done, value } = await reader.read();
            
            if (done) {
              console.log('[STREAMING] ZakoÅ„czono odczyt strumienia');
              break;
            }
            
            // Dekoduj chunk
            buffer += decoder.decode(value, { stream: true });
            const lines = buffer.split('\n');
            
            // Zachowaj ostatniÄ… niepeÅ‚nÄ… liniÄ™ w buforze
            buffer = lines.pop() || '';
            
            // PrzetwÃ³rz kaÅ¼dÄ… kompletnÄ… liniÄ™
            for (const line of lines) {
              const trimmedLine = line.trim();
              
              if (trimmedLine === '') continue;
              if (trimmedLine === 'data: [DONE]') continue;
              
              if (trimmedLine.startsWith('data: ')) {
                try {
                  const jsonData = JSON.parse(trimmedLine.substring(6));
                  
                  // WyciÄ…gnij content z delta
                  const delta = jsonData.choices?.[0]?.delta;
                  if (delta?.content) {
                    const chunk = delta.content;
                    fullResponse += chunk;
                    
                    // ðŸ”¥ STREAMING CALLBACK: WywoÅ‚aj callback dla kaÅ¼dego chunka jeÅ›li jest dostarczony
                    if (onChunk && chunk) {
                      try {
                        onChunk(chunk, { 
                          totalLength: fullResponse.length,
                          isComplete: false 
                        });
                      } catch (callbackError) {
                        console.warn('[STREAMING] BÅ‚Ä…d w callback onChunk:', callbackError);
                      }
                    }
                  }
                  
                  // Zbierz statystyki uÅ¼ycia (jeÅ›li dostÄ™pne)
                  if (jsonData.usage) {
                    tokenStats = jsonData.usage;
                  }
                  
                } catch (parseError) {
                  console.warn('[STREAMING] BÅ‚Ä…d parsowania linii:', trimmedLine, parseError);
                }
              }
            }
          }
        } catch (streamError) {
          console.error('[STREAMING] BÅ‚Ä…d podczas odczytu strumienia:', streamError);
          throw new Error(`BÅ‚Ä…d streaming: ${streamError.message}`);
        }
        
        // DEBUGGING dla GPT-5
        if (modelConfig.model === 'gpt-5' && tokenStats) {
          console.log('[GPT-5 DEBUG] ðŸ“Š UÅ¼ycie tokenÃ³w (ze streaming):', {
            prompt_tokens: tokenStats.prompt_tokens,
            completion_tokens: tokenStats.completion_tokens,
            reasoning_tokens: tokenStats.completion_tokens_details?.reasoning_tokens || 0,
            output_tokens: (tokenStats.completion_tokens - (tokenStats.completion_tokens_details?.reasoning_tokens || 0))
          });
          
          // OstrzeÅ¼enie jeÅ›li reasoning zjada wszystkie tokeny
          const reasoningTokens = tokenStats.completion_tokens_details?.reasoning_tokens || 0;
          const outputTokens = tokenStats.completion_tokens - reasoningTokens;
          if (reasoningTokens > 0 && outputTokens < 100) {
            console.warn('[GPT-5 WARNING] âš ï¸ Reasoning tokens zajÄ™Å‚y prawie caÅ‚y limit!', {
              reasoning: reasoningTokens,
              output: outputTokens,
              recommendation: 'ZwiÄ™ksz max_completion_tokens lub zmniejsz reasoning_effort'
            });
          }
        }
        
        // SprawdÅº czy mamy odpowiedÅº
        if (!fullResponse || fullResponse.trim() === '') {
          console.error('[STREAMING] Pusta odpowiedÅº ze strumienia');
          throw new Error('API zwrÃ³ciÅ‚o pustÄ… odpowiedÅº przez streaming');
        }
        
        // ðŸ”¥ STREAMING CALLBACK: WywoÅ‚aj ostatni callback z flagÄ… isComplete
        if (onChunk) {
          try {
            onChunk('', { 
              totalLength: fullResponse.length,
              isComplete: true 
            });
          } catch (callbackError) {
            console.warn('[STREAMING] BÅ‚Ä…d w finalnym callback onChunk:', callbackError);
          }
        }
        
        console.log(`[STREAMING] Otrzymano odpowiedÅº: ${fullResponse.length} znakÃ³w`);
        return fullResponse;
      },
      cacheOptions
    );

    // Zapisz statystyki uÅ¼ycia modelu
    const apiEndTime = performance.now();
    const responseTime = apiEndTime - apiStartTime;
    
    try {
      SmartModelSelector.recordUsage(
        modelConfig.model,
        modelConfig.estimatedCost,
        responseTime
      );
    } catch (statsError) {
      console.warn('[callOpenAIAPI] BÅ‚Ä…d zapisywania statystyk:', statsError);
    }

    return cachedResponse;
  } catch (error) {
    console.error('BÅ‚Ä…d podczas komunikacji z API OpenAI:', error);
    throw error;
  }
};

/**
 * Formatuje wiadomoÅ›ci do wysÅ‚ania do API OpenAI wraz z danymi kontekstowymi z bazy danych
 * @param {Array} messages - Lista wiadomoÅ›ci z konwersacji
 * @param {Object} businessData - Dane biznesowe z systemu MRP
 * @param {Object} options - Opcje optymalizacji kontekstu
 * @returns {Array} - Sformatowane wiadomoÅ›ci dla API OpenAI
 */
const formatMessagesForOpenAI = (messages, businessData = null, options = {}) => {
  // NOWA OPTYMALIZACJA: Optymalizacja kontekstu na podstawie zapytania
  let optimizedBusinessData = businessData;
  
  if (businessData && options.enableOptimization !== false) {
    const userQuery = messages[messages.length - 1]?.content || '';
    const modelType = options.modelType || 'medium';
    
    try {
      optimizedBusinessData = ContextOptimizer.prepareOptimalContext(
        userQuery, 
        businessData, 
        modelType
      );
      
      console.log(`[formatMessagesForOpenAI] ${ContextOptimizer.generateOptimizationReport(optimizedBusinessData)}`);
    } catch (error) {
      console.error('[formatMessagesForOpenAI] BÅ‚Ä…d optymalizacji kontekstu:', error);
      optimizedBusinessData = businessData; // Fallback do oryginalnych danych
    }
  }

  // NOWA STRATEGIA: Kompresja kontekstu przez JSON zamiast dÅ‚ugiego tekstu
  let businessDataContext = '';
  
  if (optimizedBusinessData) {
    // Przygotuj skompresowany kontekst w formacie JSON
    const compactContext = {
      summary: optimizedBusinessData.summary || {},
      collections: {},
      analysis: optimizedBusinessData.analysis || {}
    };
    
    // Funkcja do inteligentnego przyciÄ™cia duÅ¼ych kolekcji
    // ðŸ”¥ OPTYMALIZACJA: Zmniejszono z 50 na 20 aby zmieÅ›ciÄ‡ siÄ™ w limicie 272k tokenÃ³w GPT-5
    const smartTruncate = (items, maxItems = 20) => {
      if (!Array.isArray(items)) return items;
      if (items.length <= maxItems) return items;
      
      // Dla duÅ¼ych kolekcji: pierwsze 15 + ostatnie 5 + marker
      return [
        ...items.slice(0, 15),
        { _truncated: true, _hiddenCount: items.length - 20, _message: `[${items.length - 20} more items omitted for brevity]` },
        ...items.slice(-5)
      ];
    };
    
    // ðŸ”¥ FIX: Dodaj dane z kaÅ¼dej kolekcji w formacie JSON
    // ContextOptimizer zwraca pÅ‚askÄ… strukturÄ™ {summary, recipes, inventory, ...}
    // a nie {data: {recipes, inventory}, summary}
    const dataToProcess = optimizedBusinessData.data || optimizedBusinessData;
    
    Object.keys(dataToProcess).forEach(collectionName => {
      // PomiÅ„ klucze wewnÄ™trzne i summary
      if (collectionName.startsWith('_') || collectionName === 'summary' || collectionName === 'analysis') {
        return;
      }
      
      const collectionData = dataToProcess[collectionName];
      
      if (Array.isArray(collectionData) && collectionData.length > 0) {
        compactContext.collections[collectionName] = {
          count: collectionData.length,
          items: smartTruncate(collectionData, 20)  // ðŸ”¥ OPTYMALIZACJA: Limit 20 zamiast 50
        };
      }
    });
    
    // Wygeneruj zwiÄ™zÅ‚y kontekst tekstowy z najwaÅ¼niejszymi statystykami
    const summary = compactContext.summary;
    businessDataContext = `
=== SYSTEM MRP - DATA SNAPSHOT ===

QUICK STATS:
â€¢ Inventory: ${summary.totalInventoryItems || 0} items (${summary.itemsLowOnStock || 0} low stock)
â€¢ Orders (CO): ${summary.totalOrders || 0} total
â€¢ Production (MO): ${summary.totalProductionTasks || 0} tasks (${summary.activeProductionTasks || 0} active)
â€¢ Suppliers: ${summary.totalSuppliers || 0}
â€¢ Purchase Orders (PO): ${summary.pendingPurchaseOrders || 0} pending
â€¢ Timestamp: ${summary.timestamp || new Date().toISOString()}

AVAILABLE COLLECTIONS (${Object.keys(compactContext.collections).length} total):
${Object.keys(compactContext.collections).map(name => 
  `â€¢ ${name}: ${compactContext.collections[name].count} records`
).join('\n')}

DETAILED DATA (JSON format - all data from Firebase):
\`\`\`json
${JSON.stringify(compactContext, null, 1)}
\`\`\`

ANALYSIS INSIGHTS:
${JSON.stringify(compactContext.analysis, null, 1)}

NOTE: Above data comes DIRECTLY from Firebase. All data is available.
Use item NAMES (not IDs) when presenting to users.
`;
  }
  
  // Instrukcja systemowa jako pierwszy element  
  const systemPrompt = `JesteÅ› zaawansowanym asystentem AI dla systemu MRP, specjalizujÄ…cym siÄ™ w szczegÃ³Å‚owej analizie danych biznesowych.
Wykorzystujesz dane z bazy danych Firebase, na ktÃ³rej oparty jest system MRP do przeprowadzania dokÅ‚adnych i wnikliwych analiz.

WAÅ»NE: ZAWSZE masz aktualny dostÄ™p do danych bezpoÅ›rednio z systemu MRP i musisz ZAWSZE korzystaÄ‡ z danych przekazanych ci
w tej sesji. NIGDY nie mÃ³w, Å¼e nie masz dostÄ™pu do danych, jeÅ›li sÄ… one dostÄ™pne. JeÅ›li nie znasz odpowiedzi
na podstawie aktualnych danych, powiedz, Å¼e podane dane sÄ… niewystarczajÄ…ce lub niekompletne, ale NIGDY nie mÃ³w, Å¼e
"nie masz moÅ¼liwoÅ›ci bezpoÅ›redniego przeglÄ…dania danych".

JÄ˜ZYK KOMUNIKACJI: Odpowiadaj ZAWSZE w jÄ™zyku, w ktÃ³rym zostaÅ‚o zadane pytanie. JeÅ›li pytanie jest w jÄ™zyku polskim, odpowiadaj po polsku. JeÅ›li w angielskim - po angielsku, itd.

KONTEKST BRANÅ»OWY: System jest wykorzystywany w przedsiÄ™biorstwie produkujÄ…cym suplementy diety. UwzglÄ™dniaj specyfikÄ™ tej branÅ¼y w swoich analizach (np. daty waÅ¼noÅ›ci, normy jakoÅ›ci, wymagania prawne, specyfikÄ™ produkcji).

Twoim zadaniem jest dogÅ‚Ä™bna analiza danych, zarzÄ…dzanie produkcjÄ…, stanami magazynowymi i procesami biznesowymi w przedsiÄ™biorstwie produkcyjnym. Twoje odpowiedzi powinny byÄ‡:

1. SZCZEGÃ“ÅOWE - zawsze podawaj dokÅ‚adne liczby, daty, wartoÅ›ci i opisy z danych
2. ANALITYCZNE - nie tylko opisuj dane, ale wyciÄ…gaj z nich wnioski biznesowe
3. POMOCNE - sugeruj konkretne dziaÅ‚ania i rozwiÄ…zania problemÃ³w
4. PROFESJONALNE - uÅ¼ywaj odpowiedniej terminologii z dziedziny zarzÄ…dzania produkcjÄ…
5. OPARTE NA DANYCH - zawsze bazuj na aktualnych danych z systemu, ktÃ³re sÄ… przekazywane w tej sesji
6. PRECYZYJNE - podawaj TYLKO wartoÅ›ci liczbowe, ktÃ³re faktycznie wystÄ™pujÄ… w danych. NIGDY nie zmyÅ›laj danych liczbowych, ani nie zaokrÄ…glaj wartoÅ›ci, jeÅ›li nie jest to wyraÅºnie zaznaczone

PREZENTACJA DANYCH: Przy wypisywaniu danych z bazy ZAWSZE priorytetowo podawaj nazwy (np. nazwa produktu, nazwa klienta, nazwa dostawcy) zamiast ich identyfikatorÃ³w (ID). Identyfikatory podawaj jedynie jako informacjÄ™ uzupeÅ‚niajÄ…cÄ… w nawiasie, np. "Suplement Witamina D3 (ID: 12345)".

Znasz i rozumiesz wszystkie kluczowe pojÄ™cia i skrÃ³ty w systemie MRP:
- MO (Manufacturing Orders) - Zlecenia produkcyjne
- CO (Customer Orders) - ZamÃ³wienia klientÃ³w
- PO (Purchase Orders) - ZamÃ³wienia zakupu
- LOT - Numer partii produkcyjnej lub materiaÅ‚u

Dla zadaÅ„ produkcyjnych (MO), analizuj:
- Terminy rozpoczÄ™cia i zakoÅ„czenia produkcji
- Potrzebne zasoby i materiaÅ‚y
- Status zadaÅ„ i obecny postÄ™p
- ZwiÄ…zki z zamÃ³wieniami klientÃ³w i recepturami
- EfektywnoÅ›Ä‡ i czas realizacji zadaÅ„
- Zarezerwowane partie materiaÅ‚Ã³w (LOTy) dla danego zlecenia
- PowiÄ…zania partii materiaÅ‚Ã³w z zamÃ³wieniami zakupowymi (PO)
- ZgodnoÅ›Ä‡ z wymogami jakoÅ›ci dla produkcji suplementÃ³w

Dla zamÃ³wieÅ„ klientÃ³w (CO), analizuj:
- Statusy i terminowoÅ›Ä‡ realizacji
- WartoÅ›ci zamÃ³wieÅ„ i marÅ¼e
- Produkty najczÄ™Å›ciej zamawiane
- Relacje z klientami i trendy zamÃ³wieÅ„
- PowiÄ…zania z zadaniami produkcyjnymi

Dla zamÃ³wieÅ„ zakupu (PO), analizuj:
- DostawcÃ³w i warunki zakupÃ³w
- Terminy dostaw i ich dotrzymywanie
- Statusy zamÃ³wieÅ„ i etapy realizacji
- WartoÅ›ci zamÃ³wieÅ„ i koszty materiaÅ‚Ã³w
- WpÅ‚yw na stany magazynowe
- PowiÄ…zane LOTy materiaÅ‚Ã³w zakupionych w ramach zamÃ³wienia
- Certyfikaty jakoÅ›ci i dokumentacjÄ™ surowcÃ³w do produkcji suplementÃ³w

Dla stanÃ³w magazynowych, identyfikuj:
- Produkty z niskim stanem lub brakiem
- Produkty z nadmiernym stanem
- Koszty utrzymania zapasÃ³w
- Lokalizacje magazynowe
- Surowce wymagajÄ…ce uzupeÅ‚nienia
- Partie materiaÅ‚Ã³w (LOTy) i ich iloÅ›ci
- Å¹rÃ³dÅ‚o pochodzenia partii (zamÃ³wienie zakupowe)
- Daty waÅ¼noÅ›ci surowcÃ³w i gotowych suplementÃ³w
- Status kontroli jakoÅ›ci dla partii surowcÃ³w

Dla receptur, analizuj:
- Komponenty i ich iloÅ›ci
- Koszty produkcji
- MoÅ¼liwoÅ›ci optymalizacji
- Standardy jakoÅ›ci i kontrolÄ™
- ZgodnoÅ›Ä‡ z normami dla suplementÃ³w diety
- Wymogi prawne dotyczÄ…ce skÅ‚adu i etykietowania

Masz teraz rozszerzony dostÄ™p do danych o partiach materiaÅ‚Ã³w i ich powiÄ…zaniach:
- Informacje o LOTach (numerach partii) materiaÅ‚Ã³w
- Dane o powiÄ…zanych zamÃ³wieniach zakupowych (PO) dla kaÅ¼dej partii
- Rezerwacje partii materiaÅ‚Ã³w dla zadaÅ„ produkcyjnych (MO)
- Åšledzenie przepÅ‚ywu materiaÅ‚Ã³w od zamÃ³wienia zakupowego do zadania produkcyjnego
- Status badaÅ„ laboratoryjnych dla partii surowcÃ³w i wyrobÃ³w gotowych

Gdy otrzymasz zapytanie o powiÄ…zania LOTÃ³w z zamÃ³wieniami zakupowymi, analizuj:
- KtÃ³re partie materiaÅ‚Ã³w sÄ… przypisane do jakich zadaÅ„ produkcyjnych
- Z ktÃ³rego zamÃ³wienia zakupowego pochodzi dana partia materiaÅ‚u
- Poziom wykorzystania zamÃ³wionych materiaÅ‚Ã³w w produkcji
- PoprawnoÅ›Ä‡ rezerwacji materiaÅ‚Ã³w i zgodnoÅ›Ä‡ z recepturami
- DokumentacjÄ™ jakoÅ›ciowÄ… dla partii

Zawsze podawaj DOKÅADNE dane liczbowe bez zaokrÄ…gleÅ„, chyba Å¼e jest to wyraÅºnie wymagane. Podawaj procentowe porÃ³wnania i uwzglÄ™dniaj trendy, jeÅ›li sÄ… widoczne.
PamiÄ™taj o podawaniu konkretnych nazw zamiast samych ID. Format powinien byÄ‡: "Nazwa (ID: xxx)", gdy odnoÅ›isz siÄ™ do konkretnych obiektÃ³w.

Masz peÅ‚ny dostÄ™p do bazy danych Firebase i moÅ¼esz korzystaÄ‡ z wszystkich danych zawartych w systemie MRP.
Zawsze podawaj aktualne informacje na podstawie danych z bazy, a nie ogÃ³lnej wiedzy.

UWAGA: JeÅ›li w Twojej odpowiedzi chcesz wspomnieÄ‡ o ograniczeniach dostÄ™pu do danych, powiedz np. "Na podstawie obecnie dostÄ™pnych danych nie mogÄ™ podaÄ‡ tych informacji" - ale NIGDY nie mÃ³w Å¼e "nie masz moÅ¼liwoÅ›ci bezpoÅ›redniego przeglÄ…dania danych".

Struktura danych w Firebase to:
- aiConversations - Przechowuje historiÄ™ konwersacji z asystentem AI
- counters - Liczniki uÅ¼ywane przez system
- customers - Dane klientÃ³w firmy
- inventory - Stany magazynowe produktÃ³w
- inventoryBatches - Partie magazynowe produktÃ³w
- inventorySupplierPrices - Ceny produktÃ³w od dostawcÃ³w
- inventoryTransactions - Transakcje magazynowe
- itemGroups - Grupy produktÃ³w
- notifications - Powiadomienia systemowe
- orders (CO) - ZamÃ³wienia klientÃ³w
- priceListItems - Elementy cennikÃ³w
- priceLists - Cenniki
- productionHistory - Historia produkcji
- productionTasks (MO) - Zadania produkcyjne
- purchaseOrders (PO) - ZamÃ³wienia zakupu
- recipeVersions - Wersje receptur
- recipes - Receptury produktÃ³w
- settings - Ustawienia systemu
- suppliers - Dostawcy
- users - UÅ¼ytkownicy systemu
- warehouses - Magazyny
- workstations - Stanowiska pracy
  `;
  
  let systemContent = systemPrompt;
  
  // Dodaj kontekst biznesowy, jeÅ›li jest dostÄ™pny
  if (businessDataContext) {
    systemContent += `\n\nOto aktualne dane z systemu MRP do wykorzystania w analizie:${businessDataContext}`;
  }
  
  const systemInstruction = {
    role: 'system',
    content: systemContent
  };
  
  // Limitujemy liczbÄ™ wiadomoÅ›ci do MAX_CONTEXT_MESSAGES ostatnich
  const recentMessages = messages.slice(-MAX_CONTEXT_MESSAGES);
  
  // Formatowanie wiadomoÅ›ci do formatu wymaganego przez API OpenAI
  const formattedMessages = recentMessages.map(msg => ({
    role: msg.role,
    content: msg.content
  }));
  
  return [systemInstruction, ...formattedMessages];
};

/**
 * WyciÄ…ga nazwÄ™ receptury z zapytania uÅ¼ytkownika
 * @param {string} query - Zapytanie uÅ¼ytkownika
 * @returns {string|null} - Znaleziona nazwa receptury lub null
 */
const extractRecipeName = (query) => {
  // SprawdÅº, czy query istnieje i jest stringiem
  if (!query || typeof query !== 'string') {
    return null;
  }
  
  // Wzorce do rozpoznawania zapytaÅ„ o konkretne receptury
  const patterns = [
    /receptur[aÄ™y][\s\w]*"([^"]+)"/i,       // receptura "nazwa"
    /receptur[aÄ™y][\s\w]*â€ž([^"]+)"/i,        // receptura â€žnazwa"
    /receptur[aÄ™y][\s\w]+([a-zÅ¼ÅºÄ‡Å„Ã³Å‚Ä™Ä…Å›]{3,})/i,  // receptura nazwa
    /przepis[\s\w]+([a-zÅ¼ÅºÄ‡Å„Ã³Å‚Ä™Ä…Å›]{3,})/i,   // przepis nazwa
    /receptur[aÄ™y][\s\w]+dla[\s\w]+([a-zÅ¼ÅºÄ‡Å„Ã³Å‚Ä™Ä…Å›]{3,})/i, // receptura dla nazwa
    /receptur[aÄ™y][\s\w]+produktu[\s\w]+([a-zÅ¼ÅºÄ‡Å„Ã³Å‚Ä™Ä…Å›]{3,})/i // receptura produktu nazwa
  ];
  
  for (const pattern of patterns) {
    const match = query.match(pattern);
    if (match && match[1] && match[1].length > 2) {
      return match[1].trim();
    }
  }
  
  return null;
};

// Definicja funkcji getMockResponse
/**
 * Generuje lokalne odpowiedzi asystenta na podstawie zapytania i dostÄ™pnych danych
 * @param {string} query - Zapytanie uÅ¼ytkownika
 * @param {Object} businessData - Dane biznesowe z systemu MRP (opcjonalne)
 * @returns {string} - OdpowiedÅº asystenta
 */
getMockResponse = (query, businessData = null) => {
  // JeÅ›li mamy dane biznesowe, uÅ¼ywamy ich do generowania odpowiedzi
  if (businessData && businessData.data) {
    // Dane o magazynie
    if (query.toLowerCase().includes('magazyn') || query.toLowerCase().includes('stan') || 
        query.toLowerCase().includes('produkt') || query.toLowerCase().includes('towar')) {
      
      if (businessData.data.inventory && businessData.data.inventory.length > 0) {
        const inventory = businessData.data.inventory;
        const totalItems = inventory.length;
        
        // Analiza brakÃ³w i niskich stanÃ³w
        const lowStock = businessData.analysis?.inventory?.lowStockItems || [];
        const outOfStock = businessData.analysis?.inventory?.outOfStockItems || [];
        
        if (lowStock.length > 0 || outOfStock.length > 0) {
          let response = `Na podstawie danych z systemu MRP, w magazynie znajduje siÄ™ Å‚Ä…cznie ${totalItems} pozycji. `;
          
          if (lowStock.length > 0) {
            response += `Produkty z niskim stanem magazynowym (${lowStock.length}): `;
            response += lowStock.slice(0, 3).map(item => `${item.name} (${item.quantity} szt.)`).join(', ');
            if (lowStock.length > 3) response += ` i ${lowStock.length - 3} wiÄ™cej.`;
          }
          
          if (outOfStock.length > 0) {
            response += ` Produkty niedostÄ™pne (${outOfStock.length}): `;
            response += outOfStock.slice(0, 3).map(item => item.name).join(', ');
            if (outOfStock.length > 3) response += ` i ${outOfStock.length - 3} wiÄ™cej.`;
          }
          
          return response;
        } else {
          return `W systemie MRP znajduje siÄ™ ${totalItems} pozycji magazynowych. Wszystkie produkty majÄ… wystarczajÄ…cy stan magazynowy.`;
        }
      }
    }
    
    // Dane o zamÃ³wieniach produkcyjnych
    if (query.toLowerCase().includes('produkcj') || query.toLowerCase().includes('zleceni') || 
        query.toLowerCase().includes('mo ') || query.toLowerCase().includes('zadani')) {
      
      if (businessData.data.productionTasks && businessData.data.productionTasks.length > 0) {
        const tasks = businessData.data.productionTasks;
        const tasksByStatus = businessData.analysis?.production?.tasksByStatus || {};
        const statuses = Object.keys(tasksByStatus);
        
        let response = `W systemie MRP jest ${tasks.length} zadaÅ„ produkcyjnych. `;
        
        if (statuses.length > 0) {
          response += 'Status zadaÅ„: ';
          response += statuses.map(status => `${status}: ${tasksByStatus[status]}`).join(', ');
          
          if (businessData.analysis?.production?.totalPlannedHours) {
            response += `. ÅÄ…czny planowany czas produkcji: ${businessData.analysis.production.totalPlannedHours.toFixed(1)} godzin.`;
          }
        }
        
        return response;
      }
    }
    
    // Dane o recepturach
    if (query.toLowerCase().includes('receptur') || query.toLowerCase().includes('przepis') || 
        query.toLowerCase().includes('komponent') || query.toLowerCase().includes('skÅ‚adnik')) {
      
      if (businessData.data.recipes && businessData.data.recipes.length > 0) {
        const recipes = businessData.data.recipes;
        
        // SprawdÅº czy zapytanie dotyczy konkretnej receptury
        const recipeName = query && typeof query === 'string' ? extractRecipeName(query) : null;
        if (recipeName) {
          // Szukaj receptury po nazwie
          const recipe = recipes.find(r => 
            r.name.toLowerCase().includes(recipeName.toLowerCase())
          );
          
          if (recipe) {
            let response = `ZnalazÅ‚em recepturÄ™ "${recipe.name}". `;
            
            // SprawdÅº zarÃ³wno pole components jak i ingredients
            const hasComponents = recipe.components && recipe.components.length > 0;
            const hasIngredients = recipe.ingredients && recipe.ingredients.length > 0;
            
            if (hasComponents) {
              response += `Zawiera ${recipe.components.length} komponentÃ³w. `;
              
              // Dodaj informacje o kilku pierwszych komponentach
              response += `GÅ‚Ã³wne komponenty to: `;
              response += recipe.components.slice(0, 3).map(comp => 
                `${comp.name || comp.materialName || 'Komponent'} (${comp.quantity || 1} ${comp.unit || 'szt.'})`
              ).join(', ');
              
              if (recipe.components.length > 3) {
                response += ` oraz ${recipe.components.length - 3} innych komponentÃ³w.`;
              }
            } else if (hasIngredients) {
              response += `Zawiera ${recipe.ingredients.length} skÅ‚adnikÃ³w. `;
              
              // Dodaj informacje o kilku pierwszych skÅ‚adnikach
              response += `GÅ‚Ã³wne skÅ‚adniki to: `;
              response += recipe.ingredients.slice(0, 3).map(ing => 
                `${ing.name || 'SkÅ‚adnik'} (${ing.quantity || 1} ${ing.unit || 'szt.'})`
              ).join(', ');
              
              if (recipe.ingredients.length > 3) {
                response += ` oraz ${recipe.ingredients.length - 3} innych skÅ‚adnikÃ³w.`;
              }
            } else {
              response += `Ta receptura nie ma zdefiniowanych komponentÃ³w ani skÅ‚adnikÃ³w.`;
            }
            
            return response;
          } else {
            return `Nie znalazÅ‚em receptury zawierajÄ…cej nazwÄ™ "${recipeName}" w bazie danych. W systemie jest dostÄ™pnych ${recipes.length} innych receptur.`;
          }
        }
        
        // OgÃ³lne informacje o recepturach
        const recipesWithComponents = recipes.filter(r => r.components && r.components.length > 0).length;
        
        // Dodajemy oddzielne liczenie receptur ze skÅ‚adnikami (ingredients)
        const recipesWithIngredients = recipes.filter(r => r.ingredients && r.ingredients.length > 0).length;
        
        // OgÃ³lna liczba receptur z jakimikolwiek komponentami lub skÅ‚adnikami
        const totalRecipesWithItems = recipes.filter(r => 
          (r.components && r.components.length > 0) || 
          (r.ingredients && r.ingredients.length > 0)
        ).length;
        
        let response = `W systemie MRP jest ${recipes.length} receptur. `;
        
        if (totalRecipesWithItems > 0) {
          if (recipesWithComponents > 0 && recipesWithIngredients > 0) {
            response += `${totalRecipesWithItems} z nich ma zdefiniowane elementy (${recipesWithComponents} z komponentami, ${recipesWithIngredients} ze skÅ‚adnikami). `;
          } else if (recipesWithComponents > 0) {
            response += `${recipesWithComponents} z nich ma zdefiniowane komponenty. `;
          } else if (recipesWithIngredients > 0) {
            response += `${recipesWithIngredients} z nich ma zdefiniowane skÅ‚adniki. `;
          }
        }
        
        // Dodaj informacje o kilku przykÅ‚adowych recepturach
        if (recipes.length > 0) {
          response += `PrzykÅ‚adowe receptury: `;
          response += recipes.slice(0, 3).map(r => r.name).join(', ');
          
          if (recipes.length > 3) {
            response += ` i ${recipes.length - 3} innych.`;
          }
        }
        
        return response;
      }
    }
    
    // Dane o zamÃ³wieniach klientÃ³w
    if (query.toLowerCase().includes('zamÃ³wieni') || query.toLowerCase().includes('klient') || 
        query.toLowerCase().includes('sprzedaÅ¼')) {
      
      if (businessData.data.orders && businessData.data.orders.length > 0) {
        const orders = businessData.data.orders;
        const ordersByStatus = businessData.analysis?.orders?.ordersByStatus || {};
        const statuses = Object.keys(ordersByStatus);
        
        let response = `W systemie MRP jest ${orders.length} zamÃ³wieÅ„ klientÃ³w. `;
        
        if (statuses.length > 0) {
          response += 'Status zamÃ³wieÅ„: ';
          response += statuses.map(status => `${status}: ${ordersByStatus[status]}`).join(', ');
        }
        
        if (businessData.analysis?.orders?.recentOrders?.length > 0) {
          const recentOrders = businessData.analysis.orders.recentOrders;
          response += `. Najnowsze zamÃ³wienia: `;
          response += recentOrders.slice(0, 3).map(order => `${order.customer} (${order.status}, ${order.date})`).join(', ');
        }
        
        return response;
      }
    }
  }
  
  // JeÅ›li nie mamy danych lub nie pasujÄ… do zapytania, uÅ¼ywamy standardowych odpowiedzi
  const mockResponses = [
    `Na podstawie danych w systemie MRP, mogÄ™ odpowiedzieÄ‡ na pytanie o "${query}". System jest poÅ‚Ä…czony z bazÄ… danych, ale dla peÅ‚nej funkcjonalnoÅ›ci zalecam skonfigurowanie klucza API OpenAI.`,
    `AnalizujÄ…c dane magazynowe, mogÅ‚bym powiedzieÄ‡ wiÄ™cej o "${query}". Mam dostÄ™p do bazy danych systemu MRP, ale potrzebujÄ™ klucza API OpenAI do bardziej zaawansowanych analiz.`,
    `Aby udzieliÄ‡ precyzyjnej odpowiedzi na temat "${query}", korzystam z danych w bazie systemu MRP. Dla lepszych wynikÃ³w zalecam konfiguracjÄ™ klucza API OpenAI.`,
    `System poÅ‚Ä…czony z bazÄ… danych moÅ¼e analizowaÄ‡ "${query}", ale bardziej zaawansowane funkcje wymagajÄ… klucza API OpenAI.`
  ];
  
  return mockResponses[Math.floor(Math.random() * mockResponses.length)];
};

/**
 * Pobierz historiÄ™ konwersacji dla danego uÅ¼ytkownika
 * @param {string} userId - ID uÅ¼ytkownika
 * @param {number} limitCount - Limit liczby konwersacji do pobrania
 * @returns {Promise<Array>} - Lista konwersacji
 */
export const getUserConversations = async (userId, limitCount = 10) => {
  try {
    // Korzystamy z kolekcji aiConversations
    const conversationsRef = collection(db, 'aiConversations');
    
    // OPTYMALIZACJA: Zmniejszamy rozmiar danych, dodajÄ…c limity
    // i wybierajÄ…c tylko te pola, ktÃ³re sÄ… niezbÄ™dne
    const q = query(
      conversationsRef,
      where('userId', '==', userId),
      orderBy('updatedAt', 'desc'),
      limit(limitCount)
    );
    
    // Wykonujemy tylko jedno zapytanie zamiast wielokrotnych zapytaÅ„
    const querySnapshot = await getDocs(q);
    
    // Mapujemy wyniki, ograniczajÄ…c iloÅ›Ä‡ przetwarzanych danych
    return querySnapshot.docs.map(doc => ({
      id: doc.id,
      title: doc.data().title || 'Nowa konwersacja',
      updatedAt: doc.data().updatedAt,
      messageCount: doc.data().messageCount || 0
      // Nie pobieramy peÅ‚nych treÅ›ci wiadomoÅ›ci, tylko niezbÄ™dne metadane
    }));
  } catch (error) {
    console.error('BÅ‚Ä…d podczas pobierania konwersacji uÅ¼ytkownika:', error);
    throw error;
  }
};

/**
 * Pobierz wiadomoÅ›ci dla danej konwersacji
 * @param {string} conversationId - ID konwersacji
 * @returns {Promise<Array>} - Lista wiadomoÅ›ci
 */
export const getConversationMessages = async (conversationId) => {
  try {
    const messagesRef = collection(db, 'aiConversations', conversationId, 'messages');
    const q = query(messagesRef, orderBy('timestamp', 'asc'));
    
    const querySnapshot = await getDocs(q);
    return querySnapshot.docs.map(doc => ({
      id: doc.id,
      ...doc.data()
    }));
  } catch (error) {
    console.error('BÅ‚Ä…d podczas pobierania wiadomoÅ›ci konwersacji:', error);
    throw error;
  }
};

/**
 * UtwÃ³rz nowÄ… konwersacjÄ™
 * @param {string} userId - ID uÅ¼ytkownika
 * @param {string} title - TytuÅ‚ konwersacji
 * @returns {Promise<string>} - ID utworzonej konwersacji
 */
export const createConversation = async (userId, title = 'Nowa konwersacja') => {
  try {
    const conversationsRef = collection(db, 'aiConversations');
    const docRef = await addDoc(conversationsRef, {
      userId,
      title,
      createdAt: serverTimestamp(),
      updatedAt: serverTimestamp(),
      messageCount: 0
    });
    
    return docRef.id;
  } catch (error) {
    console.error('BÅ‚Ä…d podczas tworzenia nowej konwersacji:', error);
    throw error;
  }
};

/**
 * PrzesyÅ‚a zaÅ‚Ä…cznik do Firebase Storage
 * @param {File} file - Plik do przesÅ‚ania
 * @param {string} userId - ID uÅ¼ytkownika
 * @param {string} conversationId - ID konwersacji
 * @returns {Promise<Object>} - Informacje o przesÅ‚anym pliku
 */
export const uploadAttachment = async (file, userId, conversationId) => {
  try {
    if (!file || !userId || !conversationId) {
      throw new Error('Brak wymaganych parametrÃ³w');
    }

    // SprawdÅº rozmiar pliku (maksymalnie 10 MB)
    const fileSizeInMB = file.size / (1024 * 1024);
    if (fileSizeInMB > 10) {
      throw new Error(`Plik jest zbyt duÅ¼y (${fileSizeInMB.toFixed(2)} MB). Maksymalny rozmiar to 10 MB.`);
    }

    // SprawdÅº typ pliku - dozwolone sÄ… pliki tekstowe, obrazy i dokumenty
    const allowedTypes = [
      'text/plain',
      'text/csv',
      'application/json',
      'application/pdf',
      'application/msword',
      'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
      'application/vnd.ms-excel',
      'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
      'image/jpeg',
      'image/png',
      'image/gif',
      'image/webp'
    ];

    if (!allowedTypes.includes(file.type)) {
      throw new Error(`NieobsÅ‚ugiwany typ pliku: ${file.type}. Dozwolone sÄ… pliki tekstowe, dokumenty i obrazy.`);
    }

    // Tworzymy Å›cieÅ¼kÄ™ do pliku w Firebase Storage
    const timestamp = new Date().getTime();
    const fileExtension = file.name.split('.').pop();
    const sanitizedFileName = file.name.replace(/[^a-zA-Z0-9.-]/g, '_');
    const fileName = `${timestamp}_${sanitizedFileName}`;
    const storagePath = `ai-attachments/${userId}/${conversationId}/${fileName}`;

    // PrzesyÅ‚amy plik do Firebase Storage
    const fileRef = ref(storage, storagePath);
    await uploadBytes(fileRef, file);

    // Pobieramy URL do pobrania pliku
    const downloadURL = await getDownloadURL(fileRef);

    return {
      fileName: file.name,
      storagePath,
      downloadURL,
      contentType: file.type,
      size: file.size,
      uploadedAt: new Date().toISOString()
    };
  } catch (error) {
    console.error('BÅ‚Ä…d podczas przesyÅ‚ania zaÅ‚Ä…cznika:', error);
    throw error;
  }
};

/**
 * Usuwa zaÅ‚Ä…cznik z Firebase Storage
 * @param {string} storagePath - ÅšcieÅ¼ka do pliku w Storage
 * @returns {Promise<void>}
 */
export const deleteAttachment = async (storagePath) => {
  try {
    const fileRef = ref(storage, storagePath);
    await deleteObject(fileRef);
  } catch (error) {
    console.error('BÅ‚Ä…d podczas usuwania zaÅ‚Ä…cznika:', error);
    throw error;
  }
};

/**
 * Pobiera zawartoÅ›Ä‡ pliku tekstowego z URL
 * @param {string} downloadURL - URL do pobrania pliku
 * @param {string} contentType - Typ zawartoÅ›ci pliku
 * @returns {Promise<string>} - ZawartoÅ›Ä‡ pliku jako tekst
 */
export const getFileContent = async (downloadURL, contentType) => {
  try {
    const response = await fetch(downloadURL);
    if (!response.ok) {
      throw new Error(`BÅ‚Ä…d podczas pobierania pliku: ${response.status}`);
    }

    // Dla plikÃ³w tekstowych zwracamy bezpoÅ›rednio tekst
    if (contentType.startsWith('text/') || contentType === 'application/json') {
      return await response.text();
    }

    // Dla innych typÃ³w plikÃ³w zwracamy informacje o pliku
    return `[ZaÅ‚Ä…cznik: ${contentType}, rozmiar: ${response.headers.get('content-length') || 'nieznany'}]`;
  } catch (error) {
    console.error('BÅ‚Ä…d podczas pobierania zawartoÅ›ci pliku:', error);
    return `[BÅ‚Ä…d podczas odczytywania pliku: ${error.message}]`;
  }
};

/**
 * Dodaj wiadomoÅ›Ä‡ do konwersacji z moÅ¼liwoÅ›ciÄ… zaÅ‚Ä…czenia plikÃ³w
 * @param {string} conversationId - ID konwersacji
 * @param {string} role - Rola nadawcy ('user' lub 'assistant')
 * @param {string} content - TreÅ›Ä‡ wiadomoÅ›ci
 * @param {Array} attachments - Lista zaÅ‚Ä…cznikÃ³w (opcjonalne)
 * @returns {Promise<string>} - ID dodanej wiadomoÅ›ci
 */
export const addMessageToConversation = async (conversationId, role, content, attachments = []) => {
  try {
    // Dodanie wiadomoÅ›ci
    const messagesRef = collection(db, 'aiConversations', conversationId, 'messages');
    const timestamp = new Date().toISOString();
    
    const messageData = {
      role,
      content,
      timestamp
    };

    // Dodaj zaÅ‚Ä…czniki jeÅ›li sÄ… dostÄ™pne
    if (attachments && attachments.length > 0) {
      messageData.attachments = attachments;
    }
    
    const docRef = await addDoc(messagesRef, messageData);
    
    // Aktualizacja licznika wiadomoÅ›ci i daty aktualizacji konwersacji
    const conversationRef = doc(db, 'aiConversations', conversationId);
    const conversationDoc = await getDoc(conversationRef);
    
    if (conversationDoc.exists()) {
      await updateDoc(conversationRef, {
        messageCount: (conversationDoc.data().messageCount || 0) + 1,
        updatedAt: serverTimestamp(),
        // Aktualizujemy tytuÅ‚ konwersacji na podstawie pierwszej wiadomoÅ›ci uÅ¼ytkownika
        ...(role === 'user' && conversationDoc.data().messageCount === 0 ? 
          { title: content.substring(0, 50) + (content.length > 50 ? '...' : '') } 
          : {})
      });
    }
    
    return docRef.id;
  } catch (error) {
    console.error('BÅ‚Ä…d podczas dodawania wiadomoÅ›ci do konwersacji:', error);
    throw error;
  }
};

/**
 * Funkcja przetwarzajÄ…ca zapytanie uÅ¼ytkownika i zwracajÄ…ca odpowiedÅº asystenta
 * UÅ¼ywa GPT-4o poprzez API OpenAI, wzbogacone o dane z bazy danych
 * @param {string} query - Zapytanie uÅ¼ytkownika
 * @param {Array} context - Kontekst konwersacji (poprzednie wiadomoÅ›ci)
 * @param {string} userId - ID uÅ¼ytkownika
 * @param {Array} attachments - Lista zaÅ‚Ä…cznikÃ³w (opcjonalne)
 * @returns {Promise<string>} - OdpowiedÅº asystenta
 */
export const processAIQuery = async (query, context = [], userId, attachments = [], onChunk = null) => {
  console.log('[processAIQuery] ðŸš€ Rozpoczynam przetwarzanie zapytania:', query);
  
  // ðŸ”¥ STREAMING: JeÅ›li mamy callback, loguj to
  if (onChunk) {
    console.log('[processAIQuery] Streaming wÅ‚Ä…czony - chunki bÄ™dÄ… przekazywane w czasie rzeczywistym');
  }
  
  try {
    // âœ¨ NOWY SYSTEM: AI Query Orchestrator - GPT sam decyduje jakie dane pobraÄ‡
    // SprawdÅº czy orchestrator powinien obsÅ‚uÅ¼yÄ‡ zapytanie (nie obsÅ‚uguje zaÅ‚Ä…cznikÃ³w)
    const hasAttachments = attachments && attachments.length > 0;
    const shouldUseOrchestrator = !hasAttachments && AIQueryOrchestrator.shouldHandle(query);
    
    if (shouldUseOrchestrator) {
      console.log('[processAIQuery] ðŸŽ¯ UÅ¼ywam AI Query Orchestrator - GPT zdecyduje jakie dane pobraÄ‡');
      
      try {
        // Pobierz klucz API
        const apiKey = await getOpenAIApiKey(userId);
        
        if (!apiKey) {
          return "âŒ Nie znaleziono klucza API OpenAI. ProszÄ™ skonfigurowaÄ‡ klucz w ustawieniach systemu.";
        }
        
        // UÅ¼yj orchestratora - AI sam wykona targetowane zapytania
        const orchestratorResult = await AIQueryOrchestrator.processQuery(
          query, 
          apiKey, 
          context,
          {
            model: 'gpt-4o-mini',  // Zmieniono na gpt-4o-mini dla lepszego balansu koszt/jakoÅ›Ä‡
            // Nie przekazujemy onChunk - Function Calling (tool use) wymaga braku streamingu
            // OdpowiedÅº nadal bÄ™dzie szybka dziÄ™ki targetowanym zapytaniom (~1-3s)
          }
        );
        
        if (orchestratorResult.success) {
          console.log(`[processAIQuery] âœ… Orchestrator zakoÅ„czyÅ‚ w ${orchestratorResult.processingTime.toFixed(2)}ms`);
          console.log(`[processAIQuery] ðŸ“Š Wykonano ${orchestratorResult.executedTools.length} targetowanych zapytaÅ„ do bazy`);
          console.log(`[processAIQuery] ðŸ“ Otrzymano odpowiedÅº (dÅ‚ugoÅ›Ä‡: ${orchestratorResult.response?.length} znakÃ³w):`, orchestratorResult.response?.substring(0, 200) + '...');
          
          // Dodaj informacjÄ™ o zoptymalizowanym przetwarzaniu
          let response = orchestratorResult.response;
          
          if (orchestratorResult.executedTools.length > 0) {
            const queryNames = orchestratorResult.executedTools.map(t => t.name).join(', ');
            const totalQueryTime = orchestratorResult.executedTools.reduce((sum, t) => sum + t.executionTime, 0);
            const estimatedCost = AIQueryOrchestrator.estimateCost(orchestratorResult.tokensUsed);
            
            response += `\n\n_ðŸŽ¯ Wykonano ${orchestratorResult.executedTools.length} zoptymalizowanych zapytaÅ„ do bazy (${totalQueryTime.toFixed(0)}ms)_`;
            response += `\n_âš¡ CaÅ‚kowity czas: ${orchestratorResult.processingTime.toFixed(0)}ms | Tokeny: ${orchestratorResult.tokensUsed} | Koszt: ~$${estimatedCost.toFixed(4)}_`;
          }
          
          console.log(`[processAIQuery] ðŸŽ Zwracam odpowiedÅº (dÅ‚ugoÅ›Ä‡: ${response?.length} znakÃ³w):`, response?.substring(0, 200) + '...');
          
          return response;
        } else {
          // Orchestrator nie zdoÅ‚aÅ‚ przetworzyÄ‡ - zwrÃ³Ä‡ bÅ‚Ä…d zamiast fallbacku
          console.error('[processAIQuery] âŒ Orchestrator nie zdoÅ‚aÅ‚ przetworzyÄ‡ zapytania');
          console.error('[processAIQuery] BÅ‚Ä…d:', orchestratorResult.error);
          
          return `âŒ **Nie udaÅ‚o siÄ™ przetworzyÄ‡ zapytania**\n\n` +
                 `SzczegÃ³Å‚y: ${orchestratorResult.error}\n\n` +
                 `ðŸ’¡ SprÃ³buj:\n` +
                 `â€¢ UproÅ›Ä‡ zapytanie\n` +
                 `â€¢ Zmniejsz liczbÄ™ Å¼Ä…danych elementÃ³w\n` +
                 `â€¢ Podziel zapytanie na mniejsze czÄ™Å›ci`;
        }
        
      } catch (orchestratorError) {
        console.error('[processAIQuery] âŒ BÅ‚Ä…d w Orchestrator:', orchestratorError);
        
        return `âŒ **WystÄ…piÅ‚ bÅ‚Ä…d podczas przetwarzania zapytania**\n\n` +
               `SzczegÃ³Å‚y: ${orchestratorError.message}\n\n` +
               `ðŸ’¡ SprÃ³buj ponownie lub skontaktuj siÄ™ z administratorem.`;
      }
    } else {
      if (hasAttachments) {
        console.log('[processAIQuery] ðŸ“Ž Wykryto zaÅ‚Ä…czniki - uÅ¼ywam standardowego systemu z peÅ‚nym kontekstem');
        // Kontynuuj do standardowego systemu poniÅ¼ej
      } else {
        // Zapytanie nie moÅ¼e byÄ‡ obsÅ‚uÅ¼one przez orchestrator i nie ma zaÅ‚Ä…cznikÃ³w
        console.log('[processAIQuery] ðŸ’¬ Zapytanie konwersacyjne - orchestrator nie moÅ¼e obsÅ‚uÅ¼yÄ‡');
        return `ðŸ’¬ To zapytanie wyglÄ…da na konwersacyjne lub ogÃ³lne.\n\n` +
               `System jest zoptymalizowany pod zapytania o dane (receptury, magazyn, zamÃ³wienia, produkcja).\n\n` +
               `ðŸ’¡ SprÃ³buj zadaÄ‡ konkretne pytanie o dane, na przykÅ‚ad:\n` +
               `â€¢ "PokaÅ¼ 10 ostatnich MO"\n` +
               `â€¢ "Ile mamy receptur?"\n` +
               `â€¢ "KtÃ³re partie wygasajÄ… wkrÃ³tce?"\n` +
               `â€¢ "Jaki jest stan magazynowy?"\n\n` +
               `Lub dodaj zaÅ‚Ä…cznik, aby uÅ¼yÄ‡ peÅ‚nego kontekstu systemu.`;
      }
    }
  } catch (error) {
    console.error('[processAIQuery] âŒ BÅ‚Ä…d podczas wyboru systemu:', error);
    return `âŒ **WystÄ…piÅ‚ nieoczekiwany bÅ‚Ä…d**\n\n` +
           `SzczegÃ³Å‚y: ${error.message}\n\n` +
           `ðŸ’¡ SprÃ³buj ponownie lub skontaktuj siÄ™ z administratorem.`;
  }
  
  // STANDARDOWY SYSTEM - TYLKO dla zaÅ‚Ä…cznikÃ³w
  console.log('[processAIQuery] ðŸ“š UÅ¼ywam standardowego systemu z peÅ‚nym kontekstem danych (zaÅ‚Ä…czniki)');
  
  // Limit czasu na pobranie danych (w milisekundach) - zoptymalizowany
  const DATA_FETCH_TIMEOUT = 8000;
  
  // Å¹rÃ³dÅ‚a danych - bufor do Å›ledzenia czy dane zostaÅ‚y pobrane
  const dataSources = {
    'businessData': { ready: false, data: null },
    'apiKey': { ready: false, data: null }
  };
  
  try {
    // Wystartuj odliczanie dla limitu czasu - gdy czas upÅ‚ynie, uÅ¼yjemy dostÄ™pnych danych
    const timeoutPromise = new Promise(resolve => {
      setTimeout(() => {
        console.log('UpÅ‚ynÄ…Å‚ limit czasu na pobranie danych, generujÄ™ odpowiedÅº z dostÄ™pnymi danymi');
        resolve();
      }, DATA_FETCH_TIMEOUT);
    });
    
    // RÃ³wnolegÅ‚e pobieranie danych
    const businessDataPromise = Promise.resolve().then(async () => {
      try {
        // Przekazujemy zapytanie uÅ¼ytkownika do funkcji pobierajÄ…cej dane
        const data = await prepareBusinessDataForAI(query);
        dataSources.businessData = { ready: true, data };
        console.log('Dane biznesowe zostaÅ‚y pomyÅ›lnie pobrane z peÅ‚nymi szczegÃ³Å‚ami');
      } catch (error) {
        console.error('BÅ‚Ä…d podczas pobierania danych biznesowych:', error);
        dataSources.businessData = { ready: true, data: null };
      }
    });
    
    const apiKeyPromise = Promise.resolve().then(async () => {
      try {
        const apiKey = await getOpenAIApiKey(userId);
        dataSources.apiKey = { ready: true, data: apiKey };
      } catch (error) {
        console.error('BÅ‚Ä…d podczas pobierania klucza API:', error);
        dataSources.apiKey = { ready: true, data: null };
      }
    });
    
    // Poczekaj na wszystkie procesy lub na upÅ‚yw limitu czasu
    await Promise.race([
      Promise.all([businessDataPromise, apiKeyPromise]),
      timeoutPromise
    ]);
    
    // Pobierz dostÄ™pne dane
    const businessData = dataSources.businessData.data;
    const apiKey = dataSources.apiKey.data;
    
    // SprawdÅº czy nadal trwa pobieranie danych
    const isDataFetchingActive = !dataSources.businessData.ready || 
                                 !dataSources.apiKey.ready;
    
    // JeÅ›li dane sÄ… nadal pobierane, a nie mamy klucza API lub musimy go uÅ¼yÄ‡
    if (isDataFetchingActive && (!apiKey || query.toLowerCase().includes('dane') || query.toLowerCase().includes('system'))) {
      // Wygeneruj tymczasowÄ… odpowiedÅº
      return `PracujÄ™ nad szczegÃ³Å‚owÄ… analizÄ… danych dla Twojego zapytania "${query}". Pobieram wszystkie dostÄ™pne dane z systemu MRP, aby zapewniÄ‡ peÅ‚ne i dokÅ‚adne informacje. To moÅ¼e potrwaÄ‡ chwilÄ™ ze wzglÄ™du na duÅ¼Ä… iloÅ›Ä‡ danych. ProszÄ™ o cierpliwoÅ›Ä‡.`;
    }
    
    // JeÅ›li nie ma klucza API, uÅ¼ywamy funkcji z danymi lokalnymi
    if (!apiKey) {
      console.log('Brak klucza API - generujÄ™ odpowiedÅº lokalnie');
      return getMockResponse(query, businessData);
    }
    
    // Przygotowanie treÅ›ci zapytania z zaÅ‚Ä…cznikami
    let queryWithAttachments = query;
    
    if (attachments && attachments.length > 0) {
      queryWithAttachments += '\n\n--- ZaÅ‚Ä…czone pliki ---\n';
      
      for (const attachment of attachments) {
        try {
          queryWithAttachments += `\nPlik: ${attachment.fileName} (${attachment.contentType})\n`;
          
          // JeÅ›li to plik tekstowy, pobierz jego zawartoÅ›Ä‡
          if (attachment.contentType.startsWith('text/') || attachment.contentType === 'application/json') {
            const fileContent = await getFileContent(attachment.downloadURL, attachment.contentType);
            queryWithAttachments += `ZawartoÅ›Ä‡:\n${fileContent}\n`;
          } else if (attachment.contentType.startsWith('image/')) {
            queryWithAttachments += `[Obraz: ${attachment.fileName}]\n`;
          } else {
            queryWithAttachments += `[Dokument: ${attachment.fileName}]\n`;
          }
        } catch (error) {
          console.error('BÅ‚Ä…d podczas przetwarzania zaÅ‚Ä…cznika:', error);
          queryWithAttachments += `[BÅ‚Ä…d podczas odczytywania pliku: ${attachment.fileName}]\n`;
        }
      }
    }
    
    // Przygotowanie wiadomoÅ›ci do wysÅ‚ania z optymalizacjami
    const allMessages = [...context, { role: 'user', content: queryWithAttachments }];
    
    // OkreÅ›l poziom zÅ‚oÅ¼onoÅ›ci zapytania dla optymalizacji
    const complexity = queryWithAttachments.length > 100 ? 'complex' : 
                      queryWithAttachments.length > 50 ? 'medium' : 'simple';
    
    const formattedMessages = formatMessagesForOpenAI(allMessages, businessData, {
      enableOptimization: true,
      modelType: complexity
    });
    
    // ðŸ”¥ NOWA OPTYMALIZACJA: SprawdÅº rozmiar danych przed wysÅ‚aniem
    const messagesSize = JSON.stringify(formattedMessages).length;
    const estimatedTokens = Math.ceil(messagesSize / 3); // ~3 znaki = 1 token dla PL
    const GPT5_INPUT_LIMIT = 272000; // Limit INPUT dla GPT-5
    
    console.log(`[TOKEN CHECK] ðŸ“Š Rozmiar danych:`, {
      charactersCount: messagesSize,
      estimatedTokens: estimatedTokens,
      limit: GPT5_INPUT_LIMIT,
      utilizationPercent: ((estimatedTokens / GPT5_INPUT_LIMIT) * 100).toFixed(1) + '%',
      withinLimit: estimatedTokens <= GPT5_INPUT_LIMIT
    });
    
    // OstrzeÅ¼enie jeÅ›li zbliÅ¼amy siÄ™ do limitu
    if (estimatedTokens > GPT5_INPUT_LIMIT * 0.9) {
      console.warn(`âš ï¸ [TOKEN CHECK] UWAGA: UÅ¼ywasz ${((estimatedTokens / GPT5_INPUT_LIMIT) * 100).toFixed(1)}% limitu tokenÃ³w!`);
    }
    
    if (estimatedTokens > GPT5_INPUT_LIMIT) {
      console.error(`âŒ [TOKEN CHECK] BÅÄ„D: Przekroczono limit tokenÃ³w! ${estimatedTokens} > ${GPT5_INPUT_LIMIT}`);
      throw new Error(`Zapytanie jest zbyt duÅ¼e (${estimatedTokens} tokenÃ³w). Limit to ${GPT5_INPUT_LIMIT} tokenÃ³w. SprÃ³buj zadaÄ‡ bardziej konkretne pytanie.`);
    }
    
    console.log('WysyÅ‚am zapytanie do API OpenAI z peÅ‚nymi danymi z Firebase...');
    
    // WywoÅ‚anie API OpenAI z optymalizacjami
    try {
      const apiCallStartTime = performance.now();
      const response = await callOpenAIAPI(apiKey, formattedMessages, {
        complexity,
        optimizationOptions: {
          prioritizeSpeed: complexity === 'simple',
          prioritizeCost: true,
          enableCache: true
        }
      }, onChunk);  // ðŸ”¥ STREAMING: Przekazuj callback do API
      const apiCallEndTime = performance.now();
      const responseTime = apiCallEndTime - apiCallStartTime;
      
      console.log('Otrzymano odpowiedÅº z API OpenAI');
      
      if (!response || response.trim() === '') {
        console.error('API OpenAI zwrÃ³ciÅ‚o pustÄ… odpowiedÅº');
        return getMockResponse(query, businessData); // Fallback do lokalnej odpowiedzi
      }
      
      return response;
    } catch (apiError) {
      console.error('BÅ‚Ä…d podczas komunikacji z API OpenAI:', apiError);
      
      // SzczegÃ³Å‚owa obsÅ‚uga rÃ³Å¼nych rodzajÃ³w bÅ‚Ä™dÃ³w
      if (apiError.message.includes('Przekroczono limit zapytaÅ„')) {
        return `ðŸ˜ž Przekroczono limit zapytaÅ„ do API OpenAI. SprÃ³buj ponownie za kilka minut lub sprawdÅº ustawienia swojego konta OpenAI (https://platform.openai.com/account/limits).`;
      } else if (apiError.message.includes('Przekroczono przydziaÅ‚') || apiError.message.includes('quota') || apiError.message.includes('billing')) {
        return `âš ï¸ Przekroczono limit dostÄ™pnych Å›rodkÃ³w na koncie OpenAI. Aby kontynuowaÄ‡ korzystanie z asystenta AI, sprawdÅº swÃ³j plan i dane rozliczeniowe na stronie: https://platform.openai.com/account/billing`;
      } else if (apiError.message.includes('API')) {
        return `âŒ WystÄ…piÅ‚ bÅ‚Ä…d podczas komunikacji z API OpenAI: ${apiError.message}. SprawdÅº swÃ³j klucz API lub sprÃ³buj ponownie pÃ³Åºniej.`;
      }
      
      // Fallback do mocka w przypadku innego bÅ‚Ä™du
      return getMockResponse(query, businessData);
    }
  } catch (error) {
    console.error('BÅ‚Ä…d podczas przetwarzania zapytania przez AI:', error);
    console.error('SzczegÃ³Å‚y bÅ‚Ä™du:', error.message, error.stack);
    
    // Generowanie lokalnej odpowiedzi z informacjÄ… o bÅ‚Ä™dzie
    return `Przepraszam, ale napotkaÅ‚em problem podczas przetwarzania zapytania. SprÃ³buj ponownie za chwilÄ™ lub skontaktuj siÄ™ z administratorem systemu. (BÅ‚Ä…d: ${error.message || 'Nieznany bÅ‚Ä…d'})`;
  }
};

/**
 * UsuÅ„ konwersacjÄ™
 * @param {string} conversationId - ID konwersacji do usuniÄ™cia
 * @returns {Promise<void>}
 */
export const deleteConversation = async (conversationId) => {
  try {
    // W peÅ‚nej implementacji naleÅ¼aÅ‚oby rÃ³wnieÅ¼ usunÄ…Ä‡ wszystkie wiadomoÅ›ci w podkolekcji
    const conversationRef = doc(db, 'aiConversations', conversationId);
    await deleteDoc(conversationRef);
  } catch (error) {
    console.error('BÅ‚Ä…d podczas usuwania konwersacji:', error);
    throw error;
  }
}; 